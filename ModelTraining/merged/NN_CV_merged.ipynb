{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53a3bb9-eca2-4f94-9f38-d3fe6eaf5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import roc_curve, auc, recall_score, precision_score, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import resample\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b174531-a8c1-4c57-8abc-db06e8719b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_cohort = pd.read_csv(\"Derivation_dataset.csv\")\n",
    "external_validation_cohort = pd.read_csv(\"External_validation_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d84ade-7e1f-4ef1-b844-5dfb2f209fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_102516\\3933838254.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[el].fillna(X_train[el].mode()[0], inplace=True)\n",
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_102516\\3933838254.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[el].fillna(X_train[el].mode()[0], inplace=True)\n",
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_102516\\3933838254.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[el].fillna(X_train[el].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "y = derivation_cohort['Outcome_Occlusion_MI']\n",
    "X = derivation_cohort.drop('Outcome_Occlusion_MI', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state = 99)\n",
    "\n",
    "y_val = external_validation_cohort['Outcome_Occlusion_MI']\n",
    "X_val = external_validation_cohort.drop('Outcome_Occlusion_MI', axis=1)\n",
    "\n",
    "for el in X_train.columns:\n",
    "    X_train[el].fillna(X_train[el].mode()[0], inplace=True)\n",
    "    X_test[el].fillna(X_train[el].mode()[0], inplace=True)\n",
    "    X_val[el].fillna(X_train[el].mode()[0], inplace=True)\n",
    "\n",
    "y_train = np.ravel(np.array(y_train.values))\n",
    "y_test = np.ravel(np.array(y_test.values))\n",
    "y_val = np.ravel(np.array(y_val.values))\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "X_train = np.array(X_train.values)\n",
    "X_test = np.array(X_test.values)\n",
    "X_val = np.array(X_val.values)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train) # Compute mean and std of training set\n",
    "X_train = scaler.transform(X_train, copy=True)\n",
    "X_test = scaler.transform(X_test, copy=True) # Standardize X_test using training mean and std\n",
    "X_val = scaler.transform(X_val, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2490c8a-7d73-48bf-9f62-0e649bc3ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(99)\n",
    "np.random.seed(99)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert pandas DataFrames to NumPy arrays, then to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train.values if isinstance(X_train, pd.DataFrame) else X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values if isinstance(y_train, pd.Series) else y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val.values if isinstance(X_val, pd.DataFrame) else X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values if isinstance(y_val, pd.Series) else y_val)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor.view(-1, 1))\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor.view(-1, 1))\n",
    "\n",
    "# Get input dimensions\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616c6583-f4d1-44b9-a099-30d77a3dc082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, dropout_rate=0.3):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        # Create hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer - NO sigmoid here because we'll use BCEWithLogitsLoss\n",
    "        self.feature_layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(prev_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.feature_layers(x)\n",
    "        # Return raw logits - BCEWithLogitsLoss will handle the sigmoid internally\n",
    "        return self.output_layer(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd9473b9-cdca-46bb-a427-833b46e38c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "# Modify train_model function to return all losses for each epoch\n",
    "def train_model_with_history(model, train_loader, val_loader, criterion, optimizer, n_epochs=100, patience=5):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # To track the best model\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    # Lists to store losses for plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            # Fix dimension issue - don't double unsqueeze the labels\n",
    "            loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Calculate average training loss\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                # Fix dimension issue here too (in validation loop)\n",
    "                loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Calculate average validation loss\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Epoch {epoch+1}/{n_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping triggered after epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, train_losses, val_losses\n",
    "# Define prediction function\n",
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # Get raw logits\n",
    "            logits = model(inputs)\n",
    "            \n",
    "            # Apply sigmoid to get probabilities\n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "            predictions.append(probs.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079638e3-407a-40d2-a4d3-97d6a9866aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom ROC curve plotting function\n",
    "def plot_PyTorch_ROC_curve(fpr, tpr, roc_auc, title):\n",
    "    plt.figure(figsize=[5, 5])\n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, color='r',\n",
    "            label=f'PyTorch NN (AUC = {roc_auc:.3f})',\n",
    "            lw=2, alpha=.8)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=1, color='grey', alpha=.5)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate = 1 - Specificity')\n",
    "    plt.ylabel('True Positive Rate = Sensitivity')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613327ac-d6c9-4d3f-89c8-49cedaa2d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=1000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compute 95% confidence interval using bootstrapping for any metric.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Ground truth labels (0 or 1).\n",
    "    - y_pred: Predicted values (either probabilities or binary predictions).\n",
    "    - metric_fn: Metric function (roc_auc_score, recall_score, f1_score).\n",
    "    - n_bootstrap: Number of bootstrap resamples.\n",
    "    - alpha: Significance level (default 0.05 for 95% CI).\n",
    "\n",
    "    Returns:\n",
    "    - Lower and upper bound of the confidence interval.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample dataset with replacement\n",
    "        indices = resample(range(len(y_true)), replace=True, n_samples=len(y_true))\n",
    "        y_true_bootstrap = np.array(y_true)[indices]\n",
    "        y_pred_bootstrap = np.array(y_pred)[indices]\n",
    "\n",
    "        # Special case for AUROC: Use roc_curve and auc()\n",
    "        if metric_fn == \"auroc\":\n",
    "            fpr, tpr, _ = roc_curve(y_true_bootstrap, y_pred_bootstrap)\n",
    "            score = auc(fpr, tpr)\n",
    "        else:\n",
    "            score = metric_fn(y_true_bootstrap, y_pred_bootstrap)\n",
    "\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Compute confidence interval\n",
    "    lower_bound = np.percentile(scores, 100 * (alpha / 2))\n",
    "    upper_bound = np.percentile(scores, 100 * (1 - alpha / 2))\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f159550-e925-481d-b1c3-dfaa403f4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, best_params):\n",
    "    # Convert DataFrames to numpy arrays if needed\n",
    "    if hasattr(X_train, 'values'):\n",
    "        X_train = X_train.values\n",
    "    if hasattr(y_train, 'values'):\n",
    "        y_train = y_train.values\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.FloatTensor(X_train)\n",
    "    y_tensor = torch.FloatTensor(y_train)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=best_params['batch_size'], \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Create model with best parameters\n",
    "    model = BinaryClassifier(\n",
    "        input_dim=X_train.shape[1],\n",
    "        hidden_dims=best_params['hidden_dims'],\n",
    "        dropout_rate=best_params['dropout_rate']\n",
    "    )\n",
    "    \n",
    "    # Setup loss function and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Training\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # Training loop\n",
    "    n_epochs = 150  # You can adjust this\n",
    "    best_loss = float('inf')\n",
    "    best_model_state = model.state_dict().copy()\n",
    "    patience = 10\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    print(\"Training final model on entire dataset...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate average loss for the epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.6f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Training complete. Final loss: {best_loss:.6f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Best configuration from cross-validation\n",
    "best_params = {\n",
    "    'hidden_dims': [128, 64, 32],\n",
    "    'dropout_rate': 0.5,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'weight_decay': 0.0001\n",
    "}\n",
    "\n",
    "# Train final model on entire training set\n",
    "final_model = train_final_model(X_train, y_train, best_params)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(final_model.state_dict(), 'best_model.pt')\n",
    "print(\"Model saved to 'best_model.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8df6e819-badf-484c-b86d-d40b1f0ad42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Running 10-fold CV for 96 configurations\n",
      "Config 1/96: hidden=[64], dropout=0.6, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8250\n",
      "  Fold 2/10: AUROC = 0.8572\n",
      "  Fold 3/10: AUROC = 0.8958\n",
      "  Fold 4/10: AUROC = 0.9474\n",
      "  Fold 5/10: AUROC = 0.9044\n",
      "  Fold 6/10: AUROC = 0.9020\n",
      "  Fold 7/10: AUROC = 0.9072\n",
      "  Fold 8/10: AUROC = 0.9486\n",
      "  Fold 9/10: AUROC = 0.7384\n",
      "  Fold 10/10: AUROC = 0.8480\n",
      "  Mean AUROC: 0.8774 ± 0.0599\n",
      "Config 2/96: hidden=[64], dropout=0.6, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7823\n",
      "  Fold 2/10: AUROC = 0.8605\n",
      "  Fold 3/10: AUROC = 0.8558\n",
      "  Fold 4/10: AUROC = 0.9356\n",
      "  Fold 5/10: AUROC = 0.8875\n",
      "  Fold 6/10: AUROC = 0.8834\n",
      "  Fold 7/10: AUROC = 0.8984\n",
      "  Fold 8/10: AUROC = 0.9602\n",
      "  Fold 9/10: AUROC = 0.7395\n",
      "  Fold 10/10: AUROC = 0.8333\n",
      "  Mean AUROC: 0.8636 ± 0.0630\n",
      "Config 3/96: hidden=[64], dropout=0.6, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7556\n",
      "  Fold 2/10: AUROC = 0.8558\n",
      "  Fold 3/10: AUROC = 0.7980\n",
      "  Fold 4/10: AUROC = 0.9333\n",
      "  Fold 5/10: AUROC = 0.9261\n",
      "  Fold 6/10: AUROC = 0.8589\n",
      "  Fold 7/10: AUROC = 0.8796\n",
      "  Fold 8/10: AUROC = 0.9091\n",
      "  Fold 9/10: AUROC = 0.7226\n",
      "  Fold 10/10: AUROC = 0.8247\n",
      "  Mean AUROC: 0.8464 ± 0.0675\n",
      "Config 4/96: hidden=[64], dropout=0.6, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8374\n",
      "  Fold 2/10: AUROC = 0.8484\n",
      "  Fold 3/10: AUROC = 0.8276\n",
      "  Fold 4/10: AUROC = 0.9106\n",
      "  Fold 5/10: AUROC = 0.8920\n",
      "  Fold 6/10: AUROC = 0.9075\n",
      "  Fold 7/10: AUROC = 0.8553\n",
      "  Fold 8/10: AUROC = 0.9591\n",
      "  Fold 9/10: AUROC = 0.7167\n",
      "  Fold 10/10: AUROC = 0.8252\n",
      "  Mean AUROC: 0.8580 ± 0.0625\n",
      "Config 5/96: hidden=[64], dropout=0.6, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8025\n",
      "  Fold 2/10: AUROC = 0.8664\n",
      "  Fold 3/10: AUROC = 0.8601\n",
      "  Fold 4/10: AUROC = 0.9379\n",
      "  Fold 5/10: AUROC = 0.8813\n",
      "  Fold 6/10: AUROC = 0.8826\n",
      "  Fold 7/10: AUROC = 0.8781\n",
      "  Fold 8/10: AUROC = 0.9547\n",
      "  Fold 9/10: AUROC = 0.7667\n",
      "  Fold 10/10: AUROC = 0.8594\n",
      "  Mean AUROC: 0.8690 ± 0.0525\n",
      "Config 6/96: hidden=[64], dropout=0.6, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8028\n",
      "  Fold 2/10: AUROC = 0.8744\n",
      "  Fold 3/10: AUROC = 0.8487\n",
      "  Fold 4/10: AUROC = 0.9367\n",
      "  Fold 5/10: AUROC = 0.8748\n",
      "  Fold 6/10: AUROC = 0.9005\n",
      "  Fold 7/10: AUROC = 0.8708\n",
      "  Fold 8/10: AUROC = 0.9524\n",
      "  Fold 9/10: AUROC = 0.7976\n",
      "  Fold 10/10: AUROC = 0.8437\n",
      "  Mean AUROC: 0.8702 ± 0.0481\n",
      "Config 7/96: hidden=[64], dropout=0.6, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7886\n",
      "  Fold 2/10: AUROC = 0.8770\n",
      "  Fold 3/10: AUROC = 0.8723\n",
      "  Fold 4/10: AUROC = 0.9389\n",
      "  Fold 5/10: AUROC = 0.8720\n",
      "  Fold 6/10: AUROC = 0.9246\n",
      "  Fold 7/10: AUROC = 0.8960\n",
      "  Fold 8/10: AUROC = 0.9398\n",
      "  Fold 9/10: AUROC = 0.7599\n",
      "  Fold 10/10: AUROC = 0.8368\n",
      "  Mean AUROC: 0.8706 ± 0.0576\n",
      "Config 8/96: hidden=[64], dropout=0.6, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7897\n",
      "  Fold 2/10: AUROC = 0.8480\n",
      "  Fold 3/10: AUROC = 0.8599\n",
      "  Fold 4/10: AUROC = 0.9389\n",
      "  Fold 5/10: AUROC = 0.8763\n",
      "  Fold 6/10: AUROC = 0.8858\n",
      "  Fold 7/10: AUROC = 0.8693\n",
      "  Fold 8/10: AUROC = 0.9535\n",
      "  Fold 9/10: AUROC = 0.7320\n",
      "  Fold 10/10: AUROC = 0.8497\n",
      "  Mean AUROC: 0.8603 ± 0.0613\n",
      "Config 9/96: hidden=[64], dropout=0.7, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8007\n",
      "  Fold 2/10: AUROC = 0.8649\n",
      "  Fold 3/10: AUROC = 0.8393\n",
      "  Fold 4/10: AUROC = 0.9570\n",
      "  Fold 5/10: AUROC = 0.9096\n",
      "  Fold 6/10: AUROC = 0.9067\n",
      "  Fold 7/10: AUROC = 0.8518\n",
      "  Fold 8/10: AUROC = 0.9503\n",
      "  Fold 9/10: AUROC = 0.7210\n",
      "  Fold 10/10: AUROC = 0.8671\n",
      "  Mean AUROC: 0.8668 ± 0.0672\n",
      "Config 10/96: hidden=[64], dropout=0.7, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8075\n",
      "  Fold 2/10: AUROC = 0.8786\n",
      "  Fold 3/10: AUROC = 0.8525\n",
      "  Fold 4/10: AUROC = 0.9353\n",
      "  Fold 5/10: AUROC = 0.9074\n",
      "  Fold 6/10: AUROC = 0.9103\n",
      "  Fold 7/10: AUROC = 0.8631\n",
      "  Fold 8/10: AUROC = 0.9544\n",
      "  Fold 9/10: AUROC = 0.6653\n",
      "  Fold 10/10: AUROC = 0.8250\n",
      "  Mean AUROC: 0.8599 ± 0.0785\n",
      "Config 11/96: hidden=[64], dropout=0.7, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7970\n",
      "  Fold 2/10: AUROC = 0.8829\n",
      "  Fold 3/10: AUROC = 0.8676\n",
      "  Fold 4/10: AUROC = 0.9286\n",
      "  Fold 5/10: AUROC = 0.9074\n",
      "  Fold 6/10: AUROC = 0.9195\n",
      "  Fold 7/10: AUROC = 0.8745\n",
      "  Fold 8/10: AUROC = 0.9348\n",
      "  Fold 9/10: AUROC = 0.6737\n",
      "  Fold 10/10: AUROC = 0.8599\n",
      "  Mean AUROC: 0.8646 ± 0.0744\n",
      "Config 12/96: hidden=[64], dropout=0.7, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8326\n",
      "  Fold 2/10: AUROC = 0.8461\n",
      "  Fold 3/10: AUROC = 0.9026\n",
      "  Fold 4/10: AUROC = 0.9328\n",
      "  Fold 5/10: AUROC = 0.9119\n",
      "  Fold 6/10: AUROC = 0.9077\n",
      "  Fold 7/10: AUROC = 0.9145\n",
      "  Fold 8/10: AUROC = 0.9336\n",
      "  Fold 9/10: AUROC = 0.6562\n",
      "  Fold 10/10: AUROC = 0.8445\n",
      "  Mean AUROC: 0.8683 ± 0.0791\n",
      "Config 13/96: hidden=[64], dropout=0.7, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8033\n",
      "  Fold 2/10: AUROC = 0.8739\n",
      "  Fold 3/10: AUROC = 0.8658\n",
      "  Fold 4/10: AUROC = 0.9363\n",
      "  Fold 5/10: AUROC = 0.8915\n",
      "  Fold 6/10: AUROC = 0.9052\n",
      "  Fold 7/10: AUROC = 0.8781\n",
      "  Fold 8/10: AUROC = 0.9544\n",
      "  Fold 9/10: AUROC = 0.7481\n",
      "  Fold 10/10: AUROC = 0.8652\n",
      "  Mean AUROC: 0.8722 ± 0.0571\n",
      "Config 14/96: hidden=[64], dropout=0.7, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7906\n",
      "  Fold 2/10: AUROC = 0.8666\n",
      "  Fold 3/10: AUROC = 0.8654\n",
      "  Fold 4/10: AUROC = 0.9440\n",
      "  Fold 5/10: AUROC = 0.9141\n",
      "  Fold 6/10: AUROC = 0.9175\n",
      "  Fold 7/10: AUROC = 0.8697\n",
      "  Fold 8/10: AUROC = 0.9547\n",
      "  Fold 9/10: AUROC = 0.7774\n",
      "  Fold 10/10: AUROC = 0.8843\n",
      "  Mean AUROC: 0.8784 ± 0.0559\n",
      "Config 15/96: hidden=[64], dropout=0.7, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8192\n",
      "  Fold 2/10: AUROC = 0.8633\n",
      "  Fold 3/10: AUROC = 0.8303\n",
      "  Fold 4/10: AUROC = 0.9381\n",
      "  Fold 5/10: AUROC = 0.8855\n",
      "  Fold 6/10: AUROC = 0.8962\n",
      "  Fold 7/10: AUROC = 0.8977\n",
      "  Fold 8/10: AUROC = 0.9404\n",
      "  Fold 9/10: AUROC = 0.7188\n",
      "  Fold 10/10: AUROC = 0.8543\n",
      "  Mean AUROC: 0.8644 ± 0.0619\n",
      "Config 16/96: hidden=[64], dropout=0.7, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7983\n",
      "  Fold 2/10: AUROC = 0.8550\n",
      "  Fold 3/10: AUROC = 0.8583\n",
      "  Fold 4/10: AUROC = 0.9372\n",
      "  Fold 5/10: AUROC = 0.8930\n",
      "  Fold 6/10: AUROC = 0.8930\n",
      "  Fold 7/10: AUROC = 0.8978\n",
      "  Fold 8/10: AUROC = 0.9620\n",
      "  Fold 9/10: AUROC = 0.7634\n",
      "  Fold 10/10: AUROC = 0.8225\n",
      "  Mean AUROC: 0.8680 ± 0.0582\n",
      "Config 17/96: hidden=[128], dropout=0.6, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8358\n",
      "  Fold 2/10: AUROC = 0.8520\n",
      "  Fold 3/10: AUROC = 0.8464\n",
      "  Fold 4/10: AUROC = 0.9311\n",
      "  Fold 5/10: AUROC = 0.9246\n",
      "  Fold 6/10: AUROC = 0.9042\n",
      "  Fold 7/10: AUROC = 0.9026\n",
      "  Fold 8/10: AUROC = 0.9541\n",
      "  Fold 9/10: AUROC = 0.7312\n",
      "  Fold 10/10: AUROC = 0.8354\n",
      "  Mean AUROC: 0.8717 ± 0.0621\n",
      "Config 18/96: hidden=[128], dropout=0.6, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8227\n",
      "  Fold 2/10: AUROC = 0.8532\n",
      "  Fold 3/10: AUROC = 0.8370\n",
      "  Fold 4/10: AUROC = 0.9254\n",
      "  Fold 5/10: AUROC = 0.8954\n",
      "  Fold 6/10: AUROC = 0.8926\n",
      "  Fold 7/10: AUROC = 0.8904\n",
      "  Fold 8/10: AUROC = 0.9532\n",
      "  Fold 9/10: AUROC = 0.7626\n",
      "  Fold 10/10: AUROC = 0.8447\n",
      "  Mean AUROC: 0.8677 ± 0.0522\n",
      "Config 19/96: hidden=[128], dropout=0.6, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8073\n",
      "  Fold 2/10: AUROC = 0.8286\n",
      "  Fold 3/10: AUROC = 0.8856\n",
      "  Fold 4/10: AUROC = 0.9318\n",
      "  Fold 5/10: AUROC = 0.8748\n",
      "  Fold 6/10: AUROC = 0.9024\n",
      "  Fold 7/10: AUROC = 0.8397\n",
      "  Fold 8/10: AUROC = 0.9547\n",
      "  Fold 9/10: AUROC = 0.7239\n",
      "  Fold 10/10: AUROC = 0.8192\n",
      "  Mean AUROC: 0.8568 ± 0.0641\n",
      "Config 20/96: hidden=[128], dropout=0.6, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8285\n",
      "  Fold 2/10: AUROC = 0.8562\n",
      "  Fold 3/10: AUROC = 0.8325\n",
      "  Fold 4/10: AUROC = 0.8981\n",
      "  Fold 5/10: AUROC = 0.8755\n",
      "  Fold 6/10: AUROC = 0.8897\n",
      "  Fold 7/10: AUROC = 0.9004\n",
      "  Fold 8/10: AUROC = 0.9562\n",
      "  Fold 9/10: AUROC = 0.7242\n",
      "  Fold 10/10: AUROC = 0.8546\n",
      "  Mean AUROC: 0.8616 ± 0.0580\n",
      "Config 21/96: hidden=[128], dropout=0.6, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7565\n",
      "  Fold 2/10: AUROC = 0.8501\n",
      "  Fold 3/10: AUROC = 0.8636\n",
      "  Fold 4/10: AUROC = 0.9357\n",
      "  Fold 5/10: AUROC = 0.8999\n",
      "  Fold 6/10: AUROC = 0.9028\n",
      "  Fold 7/10: AUROC = 0.8697\n",
      "  Fold 8/10: AUROC = 0.9693\n",
      "  Fold 9/10: AUROC = 0.7027\n",
      "  Fold 10/10: AUROC = 0.8416\n",
      "  Mean AUROC: 0.8592 ± 0.0756\n",
      "Config 22/96: hidden=[128], dropout=0.6, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7942\n",
      "  Fold 2/10: AUROC = 0.8643\n",
      "  Fold 3/10: AUROC = 0.8719\n",
      "  Fold 4/10: AUROC = 0.9478\n",
      "  Fold 5/10: AUROC = 0.8994\n",
      "  Fold 6/10: AUROC = 0.9013\n",
      "  Fold 7/10: AUROC = 0.8682\n",
      "  Fold 8/10: AUROC = 0.9518\n",
      "  Fold 9/10: AUROC = 0.7618\n",
      "  Fold 10/10: AUROC = 0.8629\n",
      "  Mean AUROC: 0.8724 ± 0.0566\n",
      "Config 23/96: hidden=[128], dropout=0.6, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8031\n",
      "  Fold 2/10: AUROC = 0.8619\n",
      "  Fold 3/10: AUROC = 0.8529\n",
      "  Fold 4/10: AUROC = 0.9455\n",
      "  Fold 5/10: AUROC = 0.8862\n",
      "  Fold 6/10: AUROC = 0.8883\n",
      "  Fold 7/10: AUROC = 0.9130\n",
      "  Fold 8/10: AUROC = 0.9465\n",
      "  Fold 9/10: AUROC = 0.6780\n",
      "  Fold 10/10: AUROC = 0.8185\n",
      "  Mean AUROC: 0.8594 ± 0.0756\n",
      "Config 24/96: hidden=[128], dropout=0.6, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7899\n",
      "  Fold 2/10: AUROC = 0.8739\n",
      "  Fold 3/10: AUROC = 0.8564\n",
      "  Fold 4/10: AUROC = 0.9503\n",
      "  Fold 5/10: AUROC = 0.8969\n",
      "  Fold 6/10: AUROC = 0.8936\n",
      "  Fold 7/10: AUROC = 0.8876\n",
      "  Fold 8/10: AUROC = 0.9445\n",
      "  Fold 9/10: AUROC = 0.7702\n",
      "  Fold 10/10: AUROC = 0.8358\n",
      "  Mean AUROC: 0.8699 ± 0.0560\n",
      "Config 25/96: hidden=[128], dropout=0.7, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8171\n",
      "  Fold 2/10: AUROC = 0.8614\n",
      "  Fold 3/10: AUROC = 0.8699\n",
      "  Fold 4/10: AUROC = 0.9445\n",
      "  Fold 5/10: AUROC = 0.8770\n",
      "  Fold 6/10: AUROC = 0.9022\n",
      "  Fold 7/10: AUROC = 0.8726\n",
      "  Fold 8/10: AUROC = 0.9331\n",
      "  Fold 9/10: AUROC = 0.7105\n",
      "  Fold 10/10: AUROC = 0.8656\n",
      "  Mean AUROC: 0.8654 ± 0.0622\n",
      "Config 26/96: hidden=[128], dropout=0.7, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8098\n",
      "  Fold 2/10: AUROC = 0.8652\n",
      "  Fold 3/10: AUROC = 0.8732\n",
      "  Fold 4/10: AUROC = 0.9559\n",
      "  Fold 5/10: AUROC = 0.8979\n",
      "  Fold 6/10: AUROC = 0.9011\n",
      "  Fold 7/10: AUROC = 0.8465\n",
      "  Fold 8/10: AUROC = 0.9477\n",
      "  Fold 9/10: AUROC = 0.7659\n",
      "  Fold 10/10: AUROC = 0.8338\n",
      "  Mean AUROC: 0.8697 ± 0.0562\n",
      "Config 27/96: hidden=[128], dropout=0.7, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8328\n",
      "  Fold 2/10: AUROC = 0.8899\n",
      "  Fold 3/10: AUROC = 0.8407\n",
      "  Fold 4/10: AUROC = 0.9242\n",
      "  Fold 5/10: AUROC = 0.8723\n",
      "  Fold 6/10: AUROC = 0.9128\n",
      "  Fold 7/10: AUROC = 0.8995\n",
      "  Fold 8/10: AUROC = 0.9304\n",
      "  Fold 9/10: AUROC = 0.7000\n",
      "  Fold 10/10: AUROC = 0.8228\n",
      "  Mean AUROC: 0.8625 ± 0.0652\n",
      "Config 28/96: hidden=[128], dropout=0.7, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8598\n",
      "  Fold 2/10: AUROC = 0.8603\n",
      "  Fold 3/10: AUROC = 0.8701\n",
      "  Fold 4/10: AUROC = 0.9285\n",
      "  Fold 5/10: AUROC = 0.8788\n",
      "  Fold 6/10: AUROC = 0.9446\n",
      "  Fold 7/10: AUROC = 0.8390\n",
      "  Fold 8/10: AUROC = 0.9500\n",
      "  Fold 9/10: AUROC = 0.7763\n",
      "  Fold 10/10: AUROC = 0.8563\n",
      "  Mean AUROC: 0.8764 ± 0.0502\n",
      "Config 29/96: hidden=[128], dropout=0.7, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7940\n",
      "  Fold 2/10: AUROC = 0.8510\n",
      "  Fold 3/10: AUROC = 0.8482\n",
      "  Fold 4/10: AUROC = 0.9430\n",
      "  Fold 5/10: AUROC = 0.9243\n",
      "  Fold 6/10: AUROC = 0.9365\n",
      "  Fold 7/10: AUROC = 0.8459\n",
      "  Fold 8/10: AUROC = 0.9176\n",
      "  Fold 9/10: AUROC = 0.7723\n",
      "  Fold 10/10: AUROC = 0.8464\n",
      "  Mean AUROC: 0.8679 ± 0.0567\n",
      "Config 30/96: hidden=[128], dropout=0.7, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7651\n",
      "  Fold 2/10: AUROC = 0.8654\n",
      "  Fold 3/10: AUROC = 0.8493\n",
      "  Fold 4/10: AUROC = 0.9472\n",
      "  Fold 5/10: AUROC = 0.9119\n",
      "  Fold 6/10: AUROC = 0.9163\n",
      "  Fold 7/10: AUROC = 0.8682\n",
      "  Fold 8/10: AUROC = 0.9369\n",
      "  Fold 9/10: AUROC = 0.7841\n",
      "  Fold 10/10: AUROC = 0.8533\n",
      "  Mean AUROC: 0.8698 ± 0.0578\n",
      "Config 31/96: hidden=[128], dropout=0.7, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7957\n",
      "  Fold 2/10: AUROC = 0.8503\n",
      "  Fold 3/10: AUROC = 0.8519\n",
      "  Fold 4/10: AUROC = 0.9481\n",
      "  Fold 5/10: AUROC = 0.8763\n",
      "  Fold 6/10: AUROC = 0.9058\n",
      "  Fold 7/10: AUROC = 0.8750\n",
      "  Fold 8/10: AUROC = 0.9535\n",
      "  Fold 9/10: AUROC = 0.7245\n",
      "  Fold 10/10: AUROC = 0.8195\n",
      "  Mean AUROC: 0.8601 ± 0.0659\n",
      "Config 32/96: hidden=[128], dropout=0.7, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8084\n",
      "  Fold 2/10: AUROC = 0.8458\n",
      "  Fold 3/10: AUROC = 0.8668\n",
      "  Fold 4/10: AUROC = 0.9607\n",
      "  Fold 5/10: AUROC = 0.9049\n",
      "  Fold 6/10: AUROC = 0.9042\n",
      "  Fold 7/10: AUROC = 0.8693\n",
      "  Fold 8/10: AUROC = 0.9448\n",
      "  Fold 9/10: AUROC = 0.7446\n",
      "  Fold 10/10: AUROC = 0.8694\n",
      "  Mean AUROC: 0.8719 ± 0.0602\n",
      "Config 33/96: hidden=[256], dropout=0.6, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7912\n",
      "  Fold 2/10: AUROC = 0.8741\n",
      "  Fold 3/10: AUROC = 0.8243\n",
      "  Fold 4/10: AUROC = 0.9379\n",
      "  Fold 5/10: AUROC = 0.8847\n",
      "  Fold 6/10: AUROC = 0.8962\n",
      "  Fold 7/10: AUROC = 0.8770\n",
      "  Fold 8/10: AUROC = 0.9412\n",
      "  Fold 9/10: AUROC = 0.6648\n",
      "  Fold 10/10: AUROC = 0.8089\n",
      "  Mean AUROC: 0.8501 ± 0.0780\n",
      "Config 34/96: hidden=[256], dropout=0.6, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7925\n",
      "  Fold 2/10: AUROC = 0.8699\n",
      "  Fold 3/10: AUROC = 0.8732\n",
      "  Fold 4/10: AUROC = 0.9090\n",
      "  Fold 5/10: AUROC = 0.8952\n",
      "  Fold 6/10: AUROC = 0.8797\n",
      "  Fold 7/10: AUROC = 0.8543\n",
      "  Fold 8/10: AUROC = 0.9450\n",
      "  Fold 9/10: AUROC = 0.6763\n",
      "  Fold 10/10: AUROC = 0.8570\n",
      "  Mean AUROC: 0.8552 ± 0.0704\n",
      "Config 35/96: hidden=[256], dropout=0.6, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7805\n",
      "  Fold 2/10: AUROC = 0.8536\n",
      "  Fold 3/10: AUROC = 0.8797\n",
      "  Fold 4/10: AUROC = 0.9520\n",
      "  Fold 5/10: AUROC = 0.8636\n",
      "  Fold 6/10: AUROC = 0.8879\n",
      "  Fold 7/10: AUROC = 0.8816\n",
      "  Fold 8/10: AUROC = 0.9567\n",
      "  Fold 9/10: AUROC = 0.6621\n",
      "  Fold 10/10: AUROC = 0.8354\n",
      "  Mean AUROC: 0.8553 ± 0.0809\n",
      "Config 36/96: hidden=[256], dropout=0.6, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7775\n",
      "  Fold 2/10: AUROC = 0.8855\n",
      "  Fold 3/10: AUROC = 0.8625\n",
      "  Fold 4/10: AUROC = 0.9362\n",
      "  Fold 5/10: AUROC = 0.8571\n",
      "  Fold 6/10: AUROC = 0.8989\n",
      "  Fold 7/10: AUROC = 0.8717\n",
      "  Fold 8/10: AUROC = 0.9208\n",
      "  Fold 9/10: AUROC = 0.7651\n",
      "  Fold 10/10: AUROC = 0.8427\n",
      "  Mean AUROC: 0.8618 ± 0.0528\n",
      "Config 37/96: hidden=[256], dropout=0.6, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7222\n",
      "  Fold 2/10: AUROC = 0.8239\n",
      "  Fold 3/10: AUROC = 0.8431\n",
      "  Fold 4/10: AUROC = 0.9208\n",
      "  Fold 5/10: AUROC = 0.8852\n",
      "  Fold 6/10: AUROC = 0.8956\n",
      "  Fold 7/10: AUROC = 0.8595\n",
      "  Fold 8/10: AUROC = 0.9322\n",
      "  Fold 9/10: AUROC = 0.7349\n",
      "  Fold 10/10: AUROC = 0.8740\n",
      "  Mean AUROC: 0.8491 ± 0.0679\n",
      "Config 38/96: hidden=[256], dropout=0.6, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7720\n",
      "  Fold 2/10: AUROC = 0.8821\n",
      "  Fold 3/10: AUROC = 0.8282\n",
      "  Fold 4/10: AUROC = 0.9206\n",
      "  Fold 5/10: AUROC = 0.8857\n",
      "  Fold 6/10: AUROC = 0.8895\n",
      "  Fold 7/10: AUROC = 0.8653\n",
      "  Fold 8/10: AUROC = 0.9562\n",
      "  Fold 9/10: AUROC = 0.7968\n",
      "  Fold 10/10: AUROC = 0.8263\n",
      "  Mean AUROC: 0.8623 ± 0.0537\n",
      "Config 39/96: hidden=[256], dropout=0.6, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7669\n",
      "  Fold 2/10: AUROC = 0.8557\n",
      "  Fold 3/10: AUROC = 0.8583\n",
      "  Fold 4/10: AUROC = 0.9241\n",
      "  Fold 5/10: AUROC = 0.8740\n",
      "  Fold 6/10: AUROC = 0.8768\n",
      "  Fold 7/10: AUROC = 0.9013\n",
      "  Fold 8/10: AUROC = 0.9389\n",
      "  Fold 9/10: AUROC = 0.6892\n",
      "  Fold 10/10: AUROC = 0.8598\n",
      "  Mean AUROC: 0.8545 ± 0.0708\n",
      "Config 40/96: hidden=[256], dropout=0.6, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8132\n",
      "  Fold 2/10: AUROC = 0.8708\n",
      "  Fold 3/10: AUROC = 0.8693\n",
      "  Fold 4/10: AUROC = 0.9437\n",
      "  Fold 5/10: AUROC = 0.8823\n",
      "  Fold 6/10: AUROC = 0.8803\n",
      "  Fold 7/10: AUROC = 0.8955\n",
      "  Fold 8/10: AUROC = 0.9322\n",
      "  Fold 9/10: AUROC = 0.8242\n",
      "  Fold 10/10: AUROC = 0.8421\n",
      "  Mean AUROC: 0.8753 ± 0.0400\n",
      "Config 41/96: hidden=[256], dropout=0.7, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7733\n",
      "  Fold 2/10: AUROC = 0.8437\n",
      "  Fold 3/10: AUROC = 0.8395\n",
      "  Fold 4/10: AUROC = 0.9686\n",
      "  Fold 5/10: AUROC = 0.8964\n",
      "  Fold 6/10: AUROC = 0.9044\n",
      "  Fold 7/10: AUROC = 0.8860\n",
      "  Fold 8/10: AUROC = 0.9395\n",
      "  Fold 9/10: AUROC = 0.6927\n",
      "  Fold 10/10: AUROC = 0.7902\n",
      "  Mean AUROC: 0.8534 ± 0.0792\n",
      "Config 42/96: hidden=[256], dropout=0.7, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8078\n",
      "  Fold 2/10: AUROC = 0.8673\n",
      "  Fold 3/10: AUROC = 0.8178\n",
      "  Fold 4/10: AUROC = 0.9239\n",
      "  Fold 5/10: AUROC = 0.8890\n",
      "  Fold 6/10: AUROC = 0.8693\n",
      "  Fold 7/10: AUROC = 0.8618\n",
      "  Fold 8/10: AUROC = 0.9673\n",
      "  Fold 9/10: AUROC = 0.6882\n",
      "  Fold 10/10: AUROC = 0.8480\n",
      "  Mean AUROC: 0.8540 ± 0.0710\n",
      "Config 43/96: hidden=[256], dropout=0.7, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8088\n",
      "  Fold 2/10: AUROC = 0.8555\n",
      "  Fold 3/10: AUROC = 0.8362\n",
      "  Fold 4/10: AUROC = 0.9395\n",
      "  Fold 5/10: AUROC = 0.8840\n",
      "  Fold 6/10: AUROC = 0.9075\n",
      "  Fold 7/10: AUROC = 0.8355\n",
      "  Fold 8/10: AUROC = 0.9491\n",
      "  Fold 9/10: AUROC = 0.7000\n",
      "  Fold 10/10: AUROC = 0.8594\n",
      "  Mean AUROC: 0.8576 ± 0.0682\n",
      "Config 44/96: hidden=[256], dropout=0.7, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7899\n",
      "  Fold 2/10: AUROC = 0.8537\n",
      "  Fold 3/10: AUROC = 0.8525\n",
      "  Fold 4/10: AUROC = 0.9181\n",
      "  Fold 5/10: AUROC = 0.8803\n",
      "  Fold 6/10: AUROC = 0.8938\n",
      "  Fold 7/10: AUROC = 0.8913\n",
      "  Fold 8/10: AUROC = 0.9389\n",
      "  Fold 9/10: AUROC = 0.7317\n",
      "  Fold 10/10: AUROC = 0.8540\n",
      "  Mean AUROC: 0.8604 ± 0.0580\n",
      "Config 45/96: hidden=[256], dropout=0.7, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7823\n",
      "  Fold 2/10: AUROC = 0.8593\n",
      "  Fold 3/10: AUROC = 0.8642\n",
      "  Fold 4/10: AUROC = 0.9376\n",
      "  Fold 5/10: AUROC = 0.8803\n",
      "  Fold 6/10: AUROC = 0.9191\n",
      "  Fold 7/10: AUROC = 0.8776\n",
      "  Fold 8/10: AUROC = 0.9667\n",
      "  Fold 9/10: AUROC = 0.7476\n",
      "  Fold 10/10: AUROC = 0.8040\n",
      "  Mean AUROC: 0.8639 ± 0.0658\n",
      "Config 46/96: hidden=[256], dropout=0.7, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7970\n",
      "  Fold 2/10: AUROC = 0.8527\n",
      "  Fold 3/10: AUROC = 0.8051\n",
      "  Fold 4/10: AUROC = 0.9510\n",
      "  Fold 5/10: AUROC = 0.8815\n",
      "  Fold 6/10: AUROC = 0.8848\n",
      "  Fold 7/10: AUROC = 0.8739\n",
      "  Fold 8/10: AUROC = 0.9231\n",
      "  Fold 9/10: AUROC = 0.7632\n",
      "  Fold 10/10: AUROC = 0.8788\n",
      "  Mean AUROC: 0.8611 ± 0.0550\n",
      "Config 47/96: hidden=[256], dropout=0.7, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8089\n",
      "  Fold 2/10: AUROC = 0.8529\n",
      "  Fold 3/10: AUROC = 0.8368\n",
      "  Fold 4/10: AUROC = 0.9490\n",
      "  Fold 5/10: AUROC = 0.8765\n",
      "  Fold 6/10: AUROC = 0.9150\n",
      "  Fold 7/10: AUROC = 0.8880\n",
      "  Fold 8/10: AUROC = 0.9468\n",
      "  Fold 9/10: AUROC = 0.7016\n",
      "  Fold 10/10: AUROC = 0.8167\n",
      "  Mean AUROC: 0.8592 ± 0.0705\n",
      "Config 48/96: hidden=[256], dropout=0.7, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8108\n",
      "  Fold 2/10: AUROC = 0.8544\n",
      "  Fold 3/10: AUROC = 0.8650\n",
      "  Fold 4/10: AUROC = 0.9263\n",
      "  Fold 5/10: AUROC = 0.8927\n",
      "  Fold 6/10: AUROC = 0.8938\n",
      "  Fold 7/10: AUROC = 0.8735\n",
      "  Fold 8/10: AUROC = 0.9500\n",
      "  Fold 9/10: AUROC = 0.6815\n",
      "  Fold 10/10: AUROC = 0.8581\n",
      "  Mean AUROC: 0.8606 ± 0.0702\n",
      "Config 49/96: hidden=[64, 32], dropout=0.6, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7240\n",
      "  Fold 2/10: AUROC = 0.8760\n",
      "  Fold 3/10: AUROC = 0.8617\n",
      "  Fold 4/10: AUROC = 0.9479\n",
      "  Fold 5/10: AUROC = 0.8910\n",
      "  Fold 6/10: AUROC = 0.9199\n",
      "  Fold 7/10: AUROC = 0.8668\n",
      "  Fold 8/10: AUROC = 0.9094\n",
      "  Fold 9/10: AUROC = 0.7089\n",
      "  Fold 10/10: AUROC = 0.8384\n",
      "  Mean AUROC: 0.8544 ± 0.0752\n",
      "Config 50/96: hidden=[64, 32], dropout=0.6, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8046\n",
      "  Fold 2/10: AUROC = 0.8961\n",
      "  Fold 3/10: AUROC = 0.8041\n",
      "  Fold 4/10: AUROC = 0.9330\n",
      "  Fold 5/10: AUROC = 0.9149\n",
      "  Fold 6/10: AUROC = 0.9042\n",
      "  Fold 7/10: AUROC = 0.8551\n",
      "  Fold 8/10: AUROC = 0.9070\n",
      "  Fold 9/10: AUROC = 0.7435\n",
      "  Fold 10/10: AUROC = 0.8591\n",
      "  Mean AUROC: 0.8622 ± 0.0579\n",
      "Config 51/96: hidden=[64, 32], dropout=0.6, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7614\n",
      "  Fold 2/10: AUROC = 0.8294\n",
      "  Fold 3/10: AUROC = 0.8184\n",
      "  Fold 4/10: AUROC = 0.9107\n",
      "  Fold 5/10: AUROC = 0.9012\n",
      "  Fold 6/10: AUROC = 0.8795\n",
      "  Fold 7/10: AUROC = 0.8894\n",
      "  Fold 8/10: AUROC = 0.9638\n",
      "  Fold 9/10: AUROC = 0.7707\n",
      "  Fold 10/10: AUROC = 0.8272\n",
      "  Mean AUROC: 0.8552 ± 0.0612\n",
      "Config 52/96: hidden=[64, 32], dropout=0.6, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7594\n",
      "  Fold 2/10: AUROC = 0.8558\n",
      "  Fold 3/10: AUROC = 0.8803\n",
      "  Fold 4/10: AUROC = 0.9373\n",
      "  Fold 5/10: AUROC = 0.9216\n",
      "  Fold 6/10: AUROC = 0.8801\n",
      "  Fold 7/10: AUROC = 0.8944\n",
      "  Fold 8/10: AUROC = 0.9062\n",
      "  Fold 9/10: AUROC = 0.6742\n",
      "  Fold 10/10: AUROC = 0.8026\n",
      "  Mean AUROC: 0.8512 ± 0.0781\n",
      "Config 53/96: hidden=[64, 32], dropout=0.6, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8411\n",
      "  Fold 2/10: AUROC = 0.8529\n",
      "  Fold 3/10: AUROC = 0.8764\n",
      "  Fold 4/10: AUROC = 0.9411\n",
      "  Fold 5/10: AUROC = 0.9119\n",
      "  Fold 6/10: AUROC = 0.9220\n",
      "  Fold 7/10: AUROC = 0.8611\n",
      "  Fold 8/10: AUROC = 0.9407\n",
      "  Fold 9/10: AUROC = 0.8062\n",
      "  Fold 10/10: AUROC = 0.8579\n",
      "  Mean AUROC: 0.8811 ± 0.0433\n",
      "Config 54/96: hidden=[64, 32], dropout=0.6, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8132\n",
      "  Fold 2/10: AUROC = 0.8907\n",
      "  Fold 3/10: AUROC = 0.8711\n",
      "  Fold 4/10: AUROC = 0.9397\n",
      "  Fold 5/10: AUROC = 0.9124\n",
      "  Fold 6/10: AUROC = 0.8889\n",
      "  Fold 7/10: AUROC = 0.8889\n",
      "  Fold 8/10: AUROC = 0.9374\n",
      "  Fold 9/10: AUROC = 0.7836\n",
      "  Fold 10/10: AUROC = 0.8488\n",
      "  Mean AUROC: 0.8775 ± 0.0479\n",
      "Config 55/96: hidden=[64, 32], dropout=0.6, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7934\n",
      "  Fold 2/10: AUROC = 0.8541\n",
      "  Fold 3/10: AUROC = 0.8348\n",
      "  Fold 4/10: AUROC = 0.9554\n",
      "  Fold 5/10: AUROC = 0.9144\n",
      "  Fold 6/10: AUROC = 0.9275\n",
      "  Fold 7/10: AUROC = 0.8244\n",
      "  Fold 8/10: AUROC = 0.9567\n",
      "  Fold 9/10: AUROC = 0.6352\n",
      "  Fold 10/10: AUROC = 0.8118\n",
      "  Mean AUROC: 0.8508 ± 0.0918\n",
      "Config 56/96: hidden=[64, 32], dropout=0.6, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7901\n",
      "  Fold 2/10: AUROC = 0.8812\n",
      "  Fold 3/10: AUROC = 0.8458\n",
      "  Fold 4/10: AUROC = 0.9418\n",
      "  Fold 5/10: AUROC = 0.8947\n",
      "  Fold 6/10: AUROC = 0.8789\n",
      "  Fold 7/10: AUROC = 0.8825\n",
      "  Fold 8/10: AUROC = 0.9556\n",
      "  Fold 9/10: AUROC = 0.8336\n",
      "  Fold 10/10: AUROC = 0.8565\n",
      "  Mean AUROC: 0.8761 ± 0.0464\n",
      "Config 57/96: hidden=[64, 32], dropout=0.7, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7619\n",
      "  Fold 2/10: AUROC = 0.8418\n",
      "  Fold 3/10: AUROC = 0.8901\n",
      "  Fold 4/10: AUROC = 0.9210\n",
      "  Fold 5/10: AUROC = 0.8989\n",
      "  Fold 6/10: AUROC = 0.9103\n",
      "  Fold 7/10: AUROC = 0.8330\n",
      "  Fold 8/10: AUROC = 0.9269\n",
      "  Fold 9/10: AUROC = 0.7516\n",
      "  Fold 10/10: AUROC = 0.8382\n",
      "  Mean AUROC: 0.8574 ± 0.0600\n",
      "Config 58/96: hidden=[64, 32], dropout=0.7, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7907\n",
      "  Fold 2/10: AUROC = 0.8690\n",
      "  Fold 3/10: AUROC = 0.8840\n",
      "  Fold 4/10: AUROC = 0.9290\n",
      "  Fold 5/10: AUROC = 0.9042\n",
      "  Fold 6/10: AUROC = 0.9030\n",
      "  Fold 7/10: AUROC = 0.8739\n",
      "  Fold 8/10: AUROC = 0.9372\n",
      "  Fold 9/10: AUROC = 0.7637\n",
      "  Fold 10/10: AUROC = 0.8237\n",
      "  Mean AUROC: 0.8678 ± 0.0549\n",
      "Config 59/96: hidden=[64, 32], dropout=0.7, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7584\n",
      "  Fold 2/10: AUROC = 0.8253\n",
      "  Fold 3/10: AUROC = 0.8656\n",
      "  Fold 4/10: AUROC = 0.9069\n",
      "  Fold 5/10: AUROC = 0.8842\n",
      "  Fold 6/10: AUROC = 0.8801\n",
      "  Fold 7/10: AUROC = 0.8450\n",
      "  Fold 8/10: AUROC = 0.8799\n",
      "  Fold 9/10: AUROC = 0.6788\n",
      "  Fold 10/10: AUROC = 0.8263\n",
      "  Mean AUROC: 0.8351 ± 0.0657\n",
      "Config 60/96: hidden=[64, 32], dropout=0.7, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8497\n",
      "  Fold 2/10: AUROC = 0.8251\n",
      "  Fold 3/10: AUROC = 0.8472\n",
      "  Fold 4/10: AUROC = 0.9321\n",
      "  Fold 5/10: AUROC = 0.8656\n",
      "  Fold 6/10: AUROC = 0.8838\n",
      "  Fold 7/10: AUROC = 0.8829\n",
      "  Fold 8/10: AUROC = 0.9418\n",
      "  Fold 9/10: AUROC = 0.7237\n",
      "  Fold 10/10: AUROC = 0.8373\n",
      "  Mean AUROC: 0.8589 ± 0.0580\n",
      "Config 61/96: hidden=[64, 32], dropout=0.7, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7932\n",
      "  Fold 2/10: AUROC = 0.8817\n",
      "  Fold 3/10: AUROC = 0.8656\n",
      "  Fold 4/10: AUROC = 0.9362\n",
      "  Fold 5/10: AUROC = 0.9069\n",
      "  Fold 6/10: AUROC = 0.9032\n",
      "  Fold 7/10: AUROC = 0.8904\n",
      "  Fold 8/10: AUROC = 0.9471\n",
      "  Fold 9/10: AUROC = 0.7919\n",
      "  Fold 10/10: AUROC = 0.8738\n",
      "  Mean AUROC: 0.8790 ± 0.0495\n",
      "Config 62/96: hidden=[64, 32], dropout=0.7, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8132\n",
      "  Fold 2/10: AUROC = 0.8534\n",
      "  Fold 3/10: AUROC = 0.8568\n",
      "  Fold 4/10: AUROC = 0.9347\n",
      "  Fold 5/10: AUROC = 0.8887\n",
      "  Fold 6/10: AUROC = 0.8797\n",
      "  Fold 7/10: AUROC = 0.8759\n",
      "  Fold 8/10: AUROC = 0.9456\n",
      "  Fold 9/10: AUROC = 0.8094\n",
      "  Fold 10/10: AUROC = 0.8813\n",
      "  Mean AUROC: 0.8739 ± 0.0421\n",
      "Config 63/96: hidden=[64, 32], dropout=0.7, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8084\n",
      "  Fold 2/10: AUROC = 0.8727\n",
      "  Fold 3/10: AUROC = 0.8605\n",
      "  Fold 4/10: AUROC = 0.9565\n",
      "  Fold 5/10: AUROC = 0.9044\n",
      "  Fold 6/10: AUROC = 0.9142\n",
      "  Fold 7/10: AUROC = 0.8861\n",
      "  Fold 8/10: AUROC = 0.9553\n",
      "  Fold 9/10: AUROC = 0.7444\n",
      "  Fold 10/10: AUROC = 0.8801\n",
      "  Mean AUROC: 0.8783 ± 0.0610\n",
      "Config 64/96: hidden=[64, 32], dropout=0.7, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8134\n",
      "  Fold 2/10: AUROC = 0.8765\n",
      "  Fold 3/10: AUROC = 0.8625\n",
      "  Fold 4/10: AUROC = 0.9494\n",
      "  Fold 5/10: AUROC = 0.9291\n",
      "  Fold 6/10: AUROC = 0.9242\n",
      "  Fold 7/10: AUROC = 0.8489\n",
      "  Fold 8/10: AUROC = 0.9608\n",
      "  Fold 9/10: AUROC = 0.7497\n",
      "  Fold 10/10: AUROC = 0.8480\n",
      "  Mean AUROC: 0.8763 ± 0.0627\n",
      "Config 65/96: hidden=[128, 64], dropout=0.6, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8022\n",
      "  Fold 2/10: AUROC = 0.8421\n",
      "  Fold 3/10: AUROC = 0.8703\n",
      "  Fold 4/10: AUROC = 0.9397\n",
      "  Fold 5/10: AUROC = 0.9101\n",
      "  Fold 6/10: AUROC = 0.9187\n",
      "  Fold 7/10: AUROC = 0.8942\n",
      "  Fold 8/10: AUROC = 0.9392\n",
      "  Fold 9/10: AUROC = 0.7379\n",
      "  Fold 10/10: AUROC = 0.8071\n",
      "  Mean AUROC: 0.8661 ± 0.0639\n",
      "Config 66/96: hidden=[128, 64], dropout=0.6, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8248\n",
      "  Fold 2/10: AUROC = 0.8862\n",
      "  Fold 3/10: AUROC = 0.8470\n",
      "  Fold 4/10: AUROC = 0.9135\n",
      "  Fold 5/10: AUROC = 0.8870\n",
      "  Fold 6/10: AUROC = 0.9138\n",
      "  Fold 7/10: AUROC = 0.8993\n",
      "  Fold 8/10: AUROC = 0.9228\n",
      "  Fold 9/10: AUROC = 0.7973\n",
      "  Fold 10/10: AUROC = 0.8536\n",
      "  Mean AUROC: 0.8745 ± 0.0399\n",
      "Config 67/96: hidden=[128, 64], dropout=0.6, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8237\n",
      "  Fold 2/10: AUROC = 0.8642\n",
      "  Fold 3/10: AUROC = 0.8029\n",
      "  Fold 4/10: AUROC = 0.8860\n",
      "  Fold 5/10: AUROC = 0.8912\n",
      "  Fold 6/10: AUROC = 0.9214\n",
      "  Fold 7/10: AUROC = 0.9088\n",
      "  Fold 8/10: AUROC = 0.9263\n",
      "  Fold 9/10: AUROC = 0.6841\n",
      "  Fold 10/10: AUROC = 0.8490\n",
      "  Mean AUROC: 0.8558 ± 0.0690\n",
      "Config 68/96: hidden=[128, 64], dropout=0.6, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8570\n",
      "  Fold 2/10: AUROC = 0.8789\n",
      "  Fold 3/10: AUROC = 0.8388\n",
      "  Fold 4/10: AUROC = 0.9404\n",
      "  Fold 5/10: AUROC = 0.9119\n",
      "  Fold 6/10: AUROC = 0.9193\n",
      "  Fold 7/10: AUROC = 0.8821\n",
      "  Fold 8/10: AUROC = 0.9521\n",
      "  Fold 9/10: AUROC = 0.6755\n",
      "  Fold 10/10: AUROC = 0.8276\n",
      "  Mean AUROC: 0.8684 ± 0.0754\n",
      "Config 69/96: hidden=[128, 64], dropout=0.6, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7783\n",
      "  Fold 2/10: AUROC = 0.8690\n",
      "  Fold 3/10: AUROC = 0.8499\n",
      "  Fold 4/10: AUROC = 0.9293\n",
      "  Fold 5/10: AUROC = 0.9089\n",
      "  Fold 6/10: AUROC = 0.8989\n",
      "  Fold 7/10: AUROC = 0.9150\n",
      "  Fold 8/10: AUROC = 0.9462\n",
      "  Fold 9/10: AUROC = 0.8078\n",
      "  Fold 10/10: AUROC = 0.8752\n",
      "  Mean AUROC: 0.8779 ± 0.0508\n",
      "Config 70/96: hidden=[128, 64], dropout=0.6, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7805\n",
      "  Fold 2/10: AUROC = 0.8847\n",
      "  Fold 3/10: AUROC = 0.8556\n",
      "  Fold 4/10: AUROC = 0.9382\n",
      "  Fold 5/10: AUROC = 0.9039\n",
      "  Fold 6/10: AUROC = 0.8995\n",
      "  Fold 7/10: AUROC = 0.8617\n",
      "  Fold 8/10: AUROC = 0.9468\n",
      "  Fold 9/10: AUROC = 0.8134\n",
      "  Fold 10/10: AUROC = 0.8712\n",
      "  Mean AUROC: 0.8755 ± 0.0490\n",
      "Config 71/96: hidden=[128, 64], dropout=0.6, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8040\n",
      "  Fold 2/10: AUROC = 0.8628\n",
      "  Fold 3/10: AUROC = 0.8339\n",
      "  Fold 4/10: AUROC = 0.9335\n",
      "  Fold 5/10: AUROC = 0.8964\n",
      "  Fold 6/10: AUROC = 0.8942\n",
      "  Fold 7/10: AUROC = 0.8794\n",
      "  Fold 8/10: AUROC = 0.9386\n",
      "  Fold 9/10: AUROC = 0.7081\n",
      "  Fold 10/10: AUROC = 0.8671\n",
      "  Mean AUROC: 0.8618 ± 0.0643\n",
      "Config 72/96: hidden=[128, 64], dropout=0.6, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8078\n",
      "  Fold 2/10: AUROC = 0.8207\n",
      "  Fold 3/10: AUROC = 0.8705\n",
      "  Fold 4/10: AUROC = 0.9471\n",
      "  Fold 5/10: AUROC = 0.8962\n",
      "  Fold 6/10: AUROC = 0.8821\n",
      "  Fold 7/10: AUROC = 0.8925\n",
      "  Fold 8/10: AUROC = 0.9541\n",
      "  Fold 9/10: AUROC = 0.7613\n",
      "  Fold 10/10: AUROC = 0.8707\n",
      "  Mean AUROC: 0.8703 ± 0.0570\n",
      "Config 73/96: hidden=[128, 64], dropout=0.7, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7599\n",
      "  Fold 2/10: AUROC = 0.8440\n",
      "  Fold 3/10: AUROC = 0.8560\n",
      "  Fold 4/10: AUROC = 0.9206\n",
      "  Fold 5/10: AUROC = 0.8905\n",
      "  Fold 6/10: AUROC = 0.9254\n",
      "  Fold 7/10: AUROC = 0.8708\n",
      "  Fold 8/10: AUROC = 0.9556\n",
      "  Fold 9/10: AUROC = 0.6981\n",
      "  Fold 10/10: AUROC = 0.8947\n",
      "  Mean AUROC: 0.8616 ± 0.0747\n",
      "Config 74/96: hidden=[128, 64], dropout=0.7, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8132\n",
      "  Fold 2/10: AUROC = 0.8563\n",
      "  Fold 3/10: AUROC = 0.8407\n",
      "  Fold 4/10: AUROC = 0.9449\n",
      "  Fold 5/10: AUROC = 0.9052\n",
      "  Fold 6/10: AUROC = 0.9236\n",
      "  Fold 7/10: AUROC = 0.8688\n",
      "  Fold 8/10: AUROC = 0.9462\n",
      "  Fold 9/10: AUROC = 0.7245\n",
      "  Fold 10/10: AUROC = 0.8820\n",
      "  Mean AUROC: 0.8705 ± 0.0641\n",
      "Config 75/96: hidden=[128, 64], dropout=0.7, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7856\n",
      "  Fold 2/10: AUROC = 0.8532\n",
      "  Fold 3/10: AUROC = 0.8047\n",
      "  Fold 4/10: AUROC = 0.9144\n",
      "  Fold 5/10: AUROC = 0.9193\n",
      "  Fold 6/10: AUROC = 0.9426\n",
      "  Fold 7/10: AUROC = 0.8487\n",
      "  Fold 8/10: AUROC = 0.9044\n",
      "  Fold 9/10: AUROC = 0.6003\n",
      "  Fold 10/10: AUROC = 0.8058\n",
      "  Mean AUROC: 0.8379 ± 0.0946\n",
      "Config 76/96: hidden=[128, 64], dropout=0.7, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8295\n",
      "  Fold 2/10: AUROC = 0.8645\n",
      "  Fold 3/10: AUROC = 0.8135\n",
      "  Fold 4/10: AUROC = 0.9398\n",
      "  Fold 5/10: AUROC = 0.9188\n",
      "  Fold 6/10: AUROC = 0.9103\n",
      "  Fold 7/10: AUROC = 0.8311\n",
      "  Fold 8/10: AUROC = 0.9097\n",
      "  Fold 9/10: AUROC = 0.6804\n",
      "  Fold 10/10: AUROC = 0.8255\n",
      "  Mean AUROC: 0.8523 ± 0.0719\n",
      "Config 77/96: hidden=[128, 64], dropout=0.7, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8094\n",
      "  Fold 2/10: AUROC = 0.8659\n",
      "  Fold 3/10: AUROC = 0.8772\n",
      "  Fold 4/10: AUROC = 0.9468\n",
      "  Fold 5/10: AUROC = 0.8887\n",
      "  Fold 6/10: AUROC = 0.9089\n",
      "  Fold 7/10: AUROC = 0.8949\n",
      "  Fold 8/10: AUROC = 0.9436\n",
      "  Fold 9/10: AUROC = 0.8046\n",
      "  Fold 10/10: AUROC = 0.8594\n",
      "  Mean AUROC: 0.8800 ± 0.0458\n",
      "Config 78/96: hidden=[128, 64], dropout=0.7, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8050\n",
      "  Fold 2/10: AUROC = 0.8772\n",
      "  Fold 3/10: AUROC = 0.8533\n",
      "  Fold 4/10: AUROC = 0.9261\n",
      "  Fold 5/10: AUROC = 0.9019\n",
      "  Fold 6/10: AUROC = 0.9112\n",
      "  Fold 7/10: AUROC = 0.8500\n",
      "  Fold 8/10: AUROC = 0.9579\n",
      "  Fold 9/10: AUROC = 0.7422\n",
      "  Fold 10/10: AUROC = 0.8454\n",
      "  Mean AUROC: 0.8670 ± 0.0595\n",
      "Config 79/96: hidden=[128, 64], dropout=0.7, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8164\n",
      "  Fold 2/10: AUROC = 0.8671\n",
      "  Fold 3/10: AUROC = 0.8546\n",
      "  Fold 4/10: AUROC = 0.9462\n",
      "  Fold 5/10: AUROC = 0.8984\n",
      "  Fold 6/10: AUROC = 0.9252\n",
      "  Fold 7/10: AUROC = 0.8978\n",
      "  Fold 8/10: AUROC = 0.9255\n",
      "  Fold 9/10: AUROC = 0.6925\n",
      "  Fold 10/10: AUROC = 0.8684\n",
      "  Mean AUROC: 0.8692 ± 0.0694\n",
      "Config 80/96: hidden=[128, 64], dropout=0.7, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7844\n",
      "  Fold 2/10: AUROC = 0.8803\n",
      "  Fold 3/10: AUROC = 0.8482\n",
      "  Fold 4/10: AUROC = 0.9500\n",
      "  Fold 5/10: AUROC = 0.9009\n",
      "  Fold 6/10: AUROC = 0.9095\n",
      "  Fold 7/10: AUROC = 0.9073\n",
      "  Fold 8/10: AUROC = 0.9421\n",
      "  Fold 9/10: AUROC = 0.7981\n",
      "  Fold 10/10: AUROC = 0.8844\n",
      "  Mean AUROC: 0.8805 ± 0.0526\n",
      "Config 81/96: hidden=[256, 128], dropout=0.6, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7907\n",
      "  Fold 2/10: AUROC = 0.8553\n",
      "  Fold 3/10: AUROC = 0.8288\n",
      "  Fold 4/10: AUROC = 0.9475\n",
      "  Fold 5/10: AUROC = 0.8957\n",
      "  Fold 6/10: AUROC = 0.9046\n",
      "  Fold 7/10: AUROC = 0.8973\n",
      "  Fold 8/10: AUROC = 0.9488\n",
      "  Fold 9/10: AUROC = 0.7013\n",
      "  Fold 10/10: AUROC = 0.8518\n",
      "  Mean AUROC: 0.8622 ± 0.0715\n",
      "Config 82/96: hidden=[256, 128], dropout=0.6, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7776\n",
      "  Fold 2/10: AUROC = 0.8603\n",
      "  Fold 3/10: AUROC = 0.8936\n",
      "  Fold 4/10: AUROC = 0.9376\n",
      "  Fold 5/10: AUROC = 0.9111\n",
      "  Fold 6/10: AUROC = 0.9124\n",
      "  Fold 7/10: AUROC = 0.8730\n",
      "  Fold 8/10: AUROC = 0.9421\n",
      "  Fold 9/10: AUROC = 0.7970\n",
      "  Fold 10/10: AUROC = 0.8467\n",
      "  Mean AUROC: 0.8752 ± 0.0530\n",
      "Config 83/96: hidden=[256, 128], dropout=0.6, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8104\n",
      "  Fold 2/10: AUROC = 0.8628\n",
      "  Fold 3/10: AUROC = 0.8239\n",
      "  Fold 4/10: AUROC = 0.9242\n",
      "  Fold 5/10: AUROC = 0.8865\n",
      "  Fold 6/10: AUROC = 0.9048\n",
      "  Fold 7/10: AUROC = 0.8935\n",
      "  Fold 8/10: AUROC = 0.9386\n",
      "  Fold 9/10: AUROC = 0.6309\n",
      "  Fold 10/10: AUROC = 0.8182\n",
      "  Mean AUROC: 0.8494 ± 0.0843\n",
      "Config 84/96: hidden=[256, 128], dropout=0.6, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8127\n",
      "  Fold 2/10: AUROC = 0.8454\n",
      "  Fold 3/10: AUROC = 0.8143\n",
      "  Fold 4/10: AUROC = 0.9141\n",
      "  Fold 5/10: AUROC = 0.8785\n",
      "  Fold 6/10: AUROC = 0.8973\n",
      "  Fold 7/10: AUROC = 0.8624\n",
      "  Fold 8/10: AUROC = 0.8883\n",
      "  Fold 9/10: AUROC = 0.7285\n",
      "  Fold 10/10: AUROC = 0.7921\n",
      "  Mean AUROC: 0.8434 ± 0.0540\n",
      "Config 85/96: hidden=[256, 128], dropout=0.6, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8098\n",
      "  Fold 2/10: AUROC = 0.8602\n",
      "  Fold 3/10: AUROC = 0.8732\n",
      "  Fold 4/10: AUROC = 0.9298\n",
      "  Fold 5/10: AUROC = 0.9057\n",
      "  Fold 6/10: AUROC = 0.9336\n",
      "  Fold 7/10: AUROC = 0.8659\n",
      "  Fold 8/10: AUROC = 0.9272\n",
      "  Fold 9/10: AUROC = 0.7032\n",
      "  Fold 10/10: AUROC = 0.8644\n",
      "  Mean AUROC: 0.8673 ± 0.0661\n",
      "Config 86/96: hidden=[256, 128], dropout=0.6, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8036\n",
      "  Fold 2/10: AUROC = 0.8696\n",
      "  Fold 3/10: AUROC = 0.8728\n",
      "  Fold 4/10: AUROC = 0.9484\n",
      "  Fold 5/10: AUROC = 0.9169\n",
      "  Fold 6/10: AUROC = 0.8605\n",
      "  Fold 7/10: AUROC = 0.8518\n",
      "  Fold 8/10: AUROC = 0.9450\n",
      "  Fold 9/10: AUROC = 0.7597\n",
      "  Fold 10/10: AUROC = 0.8899\n",
      "  Mean AUROC: 0.8718 ± 0.0560\n",
      "Config 87/96: hidden=[256, 128], dropout=0.6, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8210\n",
      "  Fold 2/10: AUROC = 0.8619\n",
      "  Fold 3/10: AUROC = 0.8754\n",
      "  Fold 4/10: AUROC = 0.9308\n",
      "  Fold 5/10: AUROC = 0.8952\n",
      "  Fold 6/10: AUROC = 0.9054\n",
      "  Fold 7/10: AUROC = 0.9110\n",
      "  Fold 8/10: AUROC = 0.9398\n",
      "  Fold 9/10: AUROC = 0.7172\n",
      "  Fold 10/10: AUROC = 0.8177\n",
      "  Mean AUROC: 0.8675 ± 0.0638\n",
      "Config 88/96: hidden=[256, 128], dropout=0.6, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8104\n",
      "  Fold 2/10: AUROC = 0.8812\n",
      "  Fold 3/10: AUROC = 0.8427\n",
      "  Fold 4/10: AUROC = 0.9356\n",
      "  Fold 5/10: AUROC = 0.8964\n",
      "  Fold 6/10: AUROC = 0.9199\n",
      "  Fold 7/10: AUROC = 0.8993\n",
      "  Fold 8/10: AUROC = 0.9266\n",
      "  Fold 9/10: AUROC = 0.7823\n",
      "  Fold 10/10: AUROC = 0.8666\n",
      "  Mean AUROC: 0.8761 ± 0.0483\n",
      "Config 89/96: hidden=[256, 128], dropout=0.7, lr=0.001, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8235\n",
      "  Fold 2/10: AUROC = 0.8859\n",
      "  Fold 3/10: AUROC = 0.8260\n",
      "  Fold 4/10: AUROC = 0.9237\n",
      "  Fold 5/10: AUROC = 0.8915\n",
      "  Fold 6/10: AUROC = 0.9016\n",
      "  Fold 7/10: AUROC = 0.9156\n",
      "  Fold 8/10: AUROC = 0.9412\n",
      "  Fold 9/10: AUROC = 0.7720\n",
      "  Fold 10/10: AUROC = 0.8245\n",
      "  Mean AUROC: 0.8705 ± 0.0524\n",
      "Config 90/96: hidden=[256, 128], dropout=0.7, lr=0.001, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8134\n",
      "  Fold 2/10: AUROC = 0.8664\n",
      "  Fold 3/10: AUROC = 0.8466\n",
      "  Fold 4/10: AUROC = 0.9383\n",
      "  Fold 5/10: AUROC = 0.8930\n",
      "  Fold 6/10: AUROC = 0.9018\n",
      "  Fold 7/10: AUROC = 0.8717\n",
      "  Fold 8/10: AUROC = 0.9468\n",
      "  Fold 9/10: AUROC = 0.7435\n",
      "  Fold 10/10: AUROC = 0.8406\n",
      "  Mean AUROC: 0.8662 ± 0.0571\n",
      "Config 91/96: hidden=[256, 128], dropout=0.7, lr=0.001, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.8061\n",
      "  Fold 2/10: AUROC = 0.8616\n",
      "  Fold 3/10: AUROC = 0.7927\n",
      "  Fold 4/10: AUROC = 0.9461\n",
      "  Fold 5/10: AUROC = 0.9042\n",
      "  Fold 6/10: AUROC = 0.9455\n",
      "  Fold 7/10: AUROC = 0.8675\n",
      "  Fold 8/10: AUROC = 0.9395\n",
      "  Fold 9/10: AUROC = 0.6688\n",
      "  Fold 10/10: AUROC = 0.8556\n",
      "  Mean AUROC: 0.8587 ± 0.0819\n",
      "Config 92/96: hidden=[256, 128], dropout=0.7, lr=0.001, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7886\n",
      "  Fold 2/10: AUROC = 0.8768\n",
      "  Fold 3/10: AUROC = 0.8456\n",
      "  Fold 4/10: AUROC = 0.9138\n",
      "  Fold 5/10: AUROC = 0.9059\n",
      "  Fold 6/10: AUROC = 0.9081\n",
      "  Fold 7/10: AUROC = 0.8543\n",
      "  Fold 8/10: AUROC = 0.9483\n",
      "  Fold 9/10: AUROC = 0.6879\n",
      "  Fold 10/10: AUROC = 0.8326\n",
      "  Mean AUROC: 0.8562 ± 0.0714\n",
      "Config 93/96: hidden=[256, 128], dropout=0.7, lr=0.005, batch=64, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7775\n",
      "  Fold 2/10: AUROC = 0.8546\n",
      "  Fold 3/10: AUROC = 0.8730\n",
      "  Fold 4/10: AUROC = 0.9442\n",
      "  Fold 5/10: AUROC = 0.8969\n",
      "  Fold 6/10: AUROC = 0.9103\n",
      "  Fold 7/10: AUROC = 0.8887\n",
      "  Fold 8/10: AUROC = 0.9398\n",
      "  Fold 9/10: AUROC = 0.7866\n",
      "  Fold 10/10: AUROC = 0.8826\n",
      "  Mean AUROC: 0.8754 ± 0.0536\n",
      "Config 94/96: hidden=[256, 128], dropout=0.7, lr=0.005, batch=64, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.7833\n",
      "  Fold 2/10: AUROC = 0.8791\n",
      "  Fold 3/10: AUROC = 0.8429\n",
      "  Fold 4/10: AUROC = 0.9282\n",
      "  Fold 5/10: AUROC = 0.9014\n",
      "  Fold 6/10: AUROC = 0.8834\n",
      "  Fold 7/10: AUROC = 0.8845\n",
      "  Fold 8/10: AUROC = 0.9541\n",
      "  Fold 9/10: AUROC = 0.7855\n",
      "  Fold 10/10: AUROC = 0.8692\n",
      "  Mean AUROC: 0.8712 ± 0.0522\n",
      "Config 95/96: hidden=[256, 128], dropout=0.7, lr=0.005, batch=128, wd=0.0001\n",
      "  Fold 1/10: AUROC = 0.7757\n",
      "  Fold 2/10: AUROC = 0.8664\n",
      "  Fold 3/10: AUROC = 0.8652\n",
      "  Fold 4/10: AUROC = 0.9433\n",
      "  Fold 5/10: AUROC = 0.9044\n",
      "  Fold 6/10: AUROC = 0.9224\n",
      "  Fold 7/10: AUROC = 0.8752\n",
      "  Fold 8/10: AUROC = 0.9325\n",
      "  Fold 9/10: AUROC = 0.7919\n",
      "  Fold 10/10: AUROC = 0.8498\n",
      "  Mean AUROC: 0.8727 ± 0.0535\n",
      "Config 96/96: hidden=[256, 128], dropout=0.7, lr=0.005, batch=128, wd=0.001\n",
      "  Fold 1/10: AUROC = 0.8245\n",
      "  Fold 2/10: AUROC = 0.8593\n",
      "  Fold 3/10: AUROC = 0.8758\n",
      "  Fold 4/10: AUROC = 0.9439\n",
      "  Fold 5/10: AUROC = 0.9223\n",
      "  Fold 6/10: AUROC = 0.9073\n",
      "  Fold 7/10: AUROC = 0.8607\n",
      "  Fold 8/10: AUROC = 0.9526\n",
      "  Fold 9/10: AUROC = 0.7460\n",
      "  Fold 10/10: AUROC = 0.8657\n",
      "  Mean AUROC: 0.8758 ± 0.0581\n",
      "\n",
      "Top 5 Hyperparameter Configurations:\n",
      "   hidden_dims  dropout  learning_rate  batch_size  weight_decay  mean_auroc  \\\n",
      "52    [64, 32]      0.6          0.005          64        0.0001    0.881123   \n",
      "79   [128, 64]      0.7          0.005         128        0.0010    0.880544   \n",
      "76   [128, 64]      0.7          0.005          64        0.0001    0.879950   \n",
      "60    [64, 32]      0.7          0.005          64        0.0001    0.878999   \n",
      "13        [64]      0.7          0.005          64        0.0010    0.878426   \n",
      "\n",
      "    std_auroc  \n",
      "52   0.043286  \n",
      "79   0.052607  \n",
      "76   0.045754  \n",
      "60   0.049547  \n",
      "13   0.055911  \n",
      "\n",
      "Best Configuration:\n",
      "Hidden Dimensions: [64, 32]\n",
      "Dropout Rate: 0.6\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.0001\n",
      "Mean AUROC: 0.8811\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Binary Classifier Neural Network\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, dropout_rate=0.3):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        # Create hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        self.feature_layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(prev_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.feature_layers(x)\n",
    "        return self.output_layer(features)\n",
    "\n",
    "# Try fewer hyperparameter combinations\n",
    "def quick_cv_search(X, y):\n",
    "    # Convert DataFrames to numpy arrays if needed\n",
    "    if hasattr(X, 'values'):\n",
    "        X = X.values\n",
    "    if hasattr(y, 'values'):\n",
    "        y = y.values\n",
    "    \n",
    "    hidden_dims_options = [\n",
    "         [64], [128], [256],\n",
    "         [64, 32], [128, 64], [256, 128],\n",
    "    ]  # Keeping all 10 options\n",
    "    \n",
    "    dropout_options = [0.6, 0.7]  # 3 options instead of 5\n",
    "    \n",
    "    lr_options = [0.001, 0.005]  # 2 options instead of 4\n",
    "    \n",
    "    batch_size_options = [64, 128]  # 2 options instead of 3\n",
    "    \n",
    "    weight_decay_options = [0.0001, 0.001]  # 2 options instead of 3\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    y_tensor = torch.FloatTensor(y)\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    best_config = None\n",
    "    best_auroc = 0\n",
    "    results = []\n",
    "    \n",
    "    total_configs = len(hidden_dims_options) * len(dropout_options) * len(lr_options) * len(batch_size_options) * len(weight_decay_options)\n",
    "    print(f\"Running 10-fold CV for {total_configs} configurations\")\n",
    "    \n",
    "    # Simplified version - using fixed batch size and weight decay to test the approach\n",
    "    # Remove this section and uncomment the full search when ready\n",
    "    config_count = 0\n",
    "    for hidden_dims in hidden_dims_options:\n",
    "        for dropout in dropout_options:\n",
    "            for lr in lr_options:\n",
    "                for batch_size in batch_size_options:\n",
    "                    for weight_decay in weight_decay_options:\n",
    "                        config_count += 1\n",
    "                        print(f\"Config {config_count}/{total_configs}: hidden={hidden_dims}, dropout={dropout}, lr={lr}, batch={batch_size}, wd={weight_decay}\")\n",
    "                        fold_scores = []\n",
    "                        \n",
    "                        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                            # Create data loaders\n",
    "                            train_loader = DataLoader(\n",
    "                                TensorDataset(X_tensor, y_tensor),\n",
    "                                batch_size=batch_size,\n",
    "                                sampler=SubsetRandomSampler(train_idx)\n",
    "                            )\n",
    "                            val_loader = DataLoader(\n",
    "                                TensorDataset(X_tensor, y_tensor),\n",
    "                                batch_size=batch_size,\n",
    "                                sampler=SubsetRandomSampler(val_idx)\n",
    "                            )\n",
    "                            \n",
    "                            # Create and train model\n",
    "                            model = BinaryClassifier(X.shape[1], hidden_dims, dropout)\n",
    "                            criterion = nn.BCEWithLogitsLoss()\n",
    "                            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "                            \n",
    "                            # Train the model with a fixed initial state\n",
    "                            model = train_model(model, train_loader, val_loader, criterion, optimizer, device)\n",
    "                            \n",
    "                            # Evaluate model\n",
    "                            model.eval()\n",
    "                            all_preds = []\n",
    "                            all_labels = []\n",
    "                            \n",
    "                            with torch.no_grad():\n",
    "                                for inputs, labels in val_loader:\n",
    "                                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                                    outputs = model(inputs)\n",
    "                                    probs = torch.sigmoid(outputs)\n",
    "                                    all_preds.extend(probs.cpu().numpy().flatten())\n",
    "                                    all_labels.extend(labels.cpu().numpy().flatten())\n",
    "                            \n",
    "                            auroc = roc_auc_score(all_labels, all_preds)\n",
    "                            fold_scores.append(auroc)\n",
    "                            print(f\"  Fold {fold+1}/10: AUROC = {auroc:.4f}\")\n",
    "                        \n",
    "                        # Calculate mean performance\n",
    "                        mean_auroc = np.mean(fold_scores)\n",
    "                        std_auroc = np.std(fold_scores)\n",
    "                        print(f\"  Mean AUROC: {mean_auroc:.4f} ± {std_auroc:.4f}\")\n",
    "                        \n",
    "                        results.append({\n",
    "                            'hidden_dims': hidden_dims,\n",
    "                            'dropout': dropout,\n",
    "                            'learning_rate': lr,\n",
    "                            'batch_size': batch_size,\n",
    "                            'weight_decay': weight_decay,\n",
    "                            'mean_auroc': mean_auroc,\n",
    "                            'std_auroc': std_auroc\n",
    "                        })\n",
    "                        \n",
    "                        if mean_auroc > best_auroc:\n",
    "                            best_auroc = mean_auroc\n",
    "                            best_config = {\n",
    "                                'hidden_dims': hidden_dims,\n",
    "                                'dropout_rate': dropout,\n",
    "                                'learning_rate': lr,\n",
    "                                'batch_size': batch_size,\n",
    "                                'weight_decay': weight_decay,\n",
    "                                'mean_auroc': mean_auroc\n",
    "                            }\n",
    "    \n",
    "    results_df = pd.DataFrame(results).sort_values('mean_auroc', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 5 Hyperparameter Configurations:\")\n",
    "    print(results_df.head(5))\n",
    "    \n",
    "    print(\"\\nBest Configuration:\")\n",
    "    print(f\"Hidden Dimensions: {best_config['hidden_dims']}\")\n",
    "    print(f\"Dropout Rate: {best_config['dropout_rate']}\")\n",
    "    print(f\"Learning Rate: {best_config['learning_rate']}\")\n",
    "    print(f\"Batch Size: {best_config['batch_size']}\")\n",
    "    print(f\"Weight Decay: {best_config['weight_decay']}\")\n",
    "    print(f\"Mean AUROC: {best_config['mean_auroc']:.4f}\")\n",
    "    \n",
    "    return best_config, results_df\n",
    "\n",
    "# Simplified training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, n_epochs=30, patience=5):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Save initial state\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = model.state_dict().copy()  # Initialize with starting state\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels.float())\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        # Check early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model\n",
    "\n",
    "# Run a quick search\n",
    "best_config, results = quick_cv_search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "085717ff-41c0-4912-b286-060ff157cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(pred_probas):\n",
    "    OMI_score = np.round(pred_probas[:, 1]*100, decimals=2)\n",
    "    y_pred = np.where(OMI_score<5, 'Low risk', 'Intermediate risk')\n",
    "    y_pred = np.where(OMI_score>=20, 'High risk', y_pred)\n",
    "    \n",
    "    results = {\n",
    "        'Low risk': [np.count_nonzero(y_pred == 'Low risk')],\n",
    "        'Intermediate risk': [np.count_nonzero(y_pred == 'Intermediate risk')],\n",
    "        'High risk': [np.count_nonzero(y_pred == 'High risk')]\n",
    "    }\n",
    "    return(pd.DataFrame(data=results, index=['Count (N)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f60959e4-051e-48af-8b21-20a97ab8a28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Training final model on entire dataset...\n",
      "Epoch 5/150, Loss: 0.167280\n",
      "Epoch 10/150, Loss: 0.145126\n",
      "Epoch 15/150, Loss: 0.135004\n",
      "Epoch 20/150, Loss: 0.134149\n",
      "Epoch 25/150, Loss: 0.119101\n",
      "Epoch 30/150, Loss: 0.112662\n",
      "Epoch 35/150, Loss: 0.115448\n",
      "Epoch 40/150, Loss: 0.108696\n",
      "Epoch 45/150, Loss: 0.099834\n",
      "Epoch 50/150, Loss: 0.105790\n",
      "Epoch 55/150, Loss: 0.100268\n",
      "Epoch 60/150, Loss: 0.094446\n",
      "Epoch 65/150, Loss: 0.097423\n",
      "Epoch 70/150, Loss: 0.090551\n",
      "Epoch 75/150, Loss: 0.093081\n",
      "Epoch 80/150, Loss: 0.083452\n",
      "Early stopping triggered after epoch 83\n",
      "Training complete. Final loss: 0.080857\n",
      "Model saved to 'best_model.pt'\n"
     ]
    }
   ],
   "source": [
    "def train_final_model(X_train, y_train, best_params):\n",
    "    # Convert DataFrames to numpy arrays if needed\n",
    "    if hasattr(X_train, 'values'):\n",
    "        X_train = X_train.values\n",
    "    if hasattr(y_train, 'values'):\n",
    "        y_train = y_train.values\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.FloatTensor(X_train)\n",
    "    y_tensor = torch.FloatTensor(y_train)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=best_params['batch_size'], \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Create model with best parameters\n",
    "    model = BinaryClassifier(\n",
    "        input_dim=X_train.shape[1],\n",
    "        hidden_dims=best_params['hidden_dims'],\n",
    "        dropout_rate=best_params['dropout_rate']\n",
    "    )\n",
    "    \n",
    "    # Setup loss function and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Training\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # Training loop\n",
    "    n_epochs = 150  # You can adjust this\n",
    "    best_loss = float('inf')\n",
    "    best_model_state = model.state_dict().copy()\n",
    "    patience = 10\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    print(\"Training final model on entire dataset...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate average loss for the epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.6f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Training complete. Final loss: {best_loss:.6f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Best configuration from cross-validation\n",
    "best_params = {\n",
    "    'hidden_dims': [64, 32],\n",
    "    'dropout_rate': 0.6,\n",
    "    'learning_rate': 0.005,\n",
    "    'batch_size': 64,\n",
    "    'weight_decay': 0.0001\n",
    "}\n",
    "\n",
    "# Train final model on entire training set\n",
    "final_model = train_final_model(X_train, y_train, best_params)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(final_model.state_dict(), 'best_model.pt')\n",
    "print(\"Model saved to 'best_model.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b950f255-a712-422e-997f-571e7b5b868f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAHWCAYAAAAYSqICAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYqdJREFUeJztnQeYU9X29he99957772JSBMBKSKKwKWpIAiKICpNkCIoCGJBQRQpKkVERUG4gKCgFOm9996HPhTP97zr+5/cJJNMkplkUs77e57AJDk52dmnvHuVvXYiwzAMIYQQQohbErt/ixBCCCGAYkkIIYR4gGJJCCGEeIBiSQghhHiAYkkIIYR4gGJJCCGEeIBiSQghhHiAYkkIIYR4gGJJCCGEeIBiGUC6du0qBQsWjNNn33nnHUmUKJHf20SCD44rjm8wwPmI8zKcWb16tfbhggULJFS5efOmZM+eXb799ttgN4XYUbNmTXnzzTclLlhSLHGhefPARUkiF/tjnTRpUsmcObNUqVJF+vbtK3v27JFw5e+//1YxvnbtWrCbEhF89913MmnSJJ8+89FHH0m6dOnkueeeizEANh/JkiXTwcurr77q9ljdv39fPv74Y6lWrZruL23atPo3XsN7rnj48KF8/fXX8thjj+k5nSJFCv2ebt26yaZNm8TKvPXWWzJ58mQ5d+6cz59NZMXasN98843D81mzZsny5ctl9uzZDq83btxYcuTIEefvwcn877//6snqKw8ePNBHypQp4/z9JHZww8Ix7ty5s+AyiIqKku3bt8v3338vt27dkvfff1/69+/v9++9e/euijMegeCDDz6QN954Q44ePRrDsxEdHS2JEyfWG3W4gkFs/fr19Ti1bds24N/35JNPyq5du+TYsWNeX/d58uSRfv36yaBBgxzEcsSIEfL555+r6OEcW7lypf6OOnXqyNq1ax32g/ebN28uf/zxh7bhiSee0GO3dOlSWbRokdSrV08WL14sadKksX3mzp070qZNG93m0UcflRYtWqhgou3z58+XAwcOyIkTJyRv3rxiRf799189Nt27d5eRI0f69mGIpdXp3bs3Bgwet7t161aCtCfSuX//vhEdHR3sZugxx7F35tKlS0atWrX0/cWLF/vlux4+fGjcuXPHSAjGjx+vbT969KgRiaxatUp/3/fffx/Q77l586b+37x5c6NAgQJef27hwoXavkOHDjm8Pnz4cH394sWLDq+3a9dOX9+wYYPD6z169NDXP/nkkxjf8emnn+p7PXv2dHkv+/DDD2N85sGDB3punDx50ggmN/+vX4NFnz599Hj++++/Pn2OYulGLOvVq2eUKVPG2LRpk1G3bl0jVapURt++ffW9n376yWjWrJmRK1cuI3ny5EbhwoWNkSNH6sloT5cuXRwuMty88D04YadOnaqfw+erVq1qbNy40eWF5erm/uOPP2rb8NnSpUsbv/32m8sbSpUqVYwUKVLo90yZMsXlPt2xfv16o2nTpkbGjBmN1KlTG+XKlTMmTZrk0D94OBPbb8YFjLYkTpxY958kSRLjnXfeibGPffv2xbhJXL16Vfs/b968+ruLFClivPfeeypC9pw5c8bYu3evce/evTiLJTh+/LiRNGlSo3bt2g6v37171xg2bJh+P9qB9rzxxhv6uqt9f/PNN3qMsC8cN/M9HAuAGz6er169OkYbcMzw3s6dO/X59u3btX8LFSqkxzVHjhxGt27dVNxNzGPs/DCFE8cG+7Dn8OHDRtu2bY1MmTLpeV6jRg3j119/dSlQ8+bNM0aPHm3kyZNH29CgQQPj4MGDhjecOnXKeP75523XTcGCBfVmbz9wCkRb5s+fb1SuXNlImTKlkSVLFqNjx47aFnvQJ2nSpFGBw3mfNm1ao1WrVnqOO/elJ+Hs3Lmz/jZn3ImlKXzfffed7TUIGq4P/CZ31K9fX88rU/zwP543btzYiA8Y1KGtxYoV037NmTOn8dRTT9nE3+x//G+Pea1//fXXHvsV1wZed2WAPPfcc3pu299PlyxZYjzyyCN6L8I+cP/dtWuXw+fOnj1rdO3aVc8HnF9od8uWLWMMGn/++Wdt55YtW3zql8D4gSKEy5cvS9OmTTXu8J///Mfmkp0xY4a6UeCiw/+///67DBs2TK5fvy7jx4/3KgZy48YNeemll9QVOG7cOHWdHDlyxKN7DK6ahQsXyssvv6wxDMQunn76aXWtZMmSRbfZunWrumxy5cqlbh/EMOByyJYtm1e/Gy5puH3wecTvcubMKXv37pVff/1Vn8cFxFDgfuzRo4e6pbFvuJHgGho+fLjDtvPmzZMkSZLIM888o89v376t254+fVr7LH/+/BqXg4vr7NmzDvEkvDZz5kyXLkhfwHfgO1etWqXHNX369OrCadmypR4D/I5SpUrJzp075cMPP1T31k8//eSwD5wX+H19+vSRrFmzumwP3Gw4h7Advs+5H8qUKSNly5a1HRecI4g94Zjs3r1bvvjiC/1//fr1ei7hPEJb5syZo+3C9wJ3x/78+fNSu3Zt7WPEznAOof/wO5FA89RTTzls/95776krcMCAAeq2xrnbsWNH2bBhQ6z9eebMGalevbrG5tB3JUuW1OOJ78B3J0+ePCBtwbWK/kKcb+zYsfodiCf+9ddfep1kzJjRti3CHk2aNJFHHnlEXdmpU6fWfsa+T506pf0JcLxiA+dm5cqVxVtM926mTJlsr/3222963SJE4A68h/MTLtcXX3xRP4Pf0KlTJ4kr+E5c+3AP476H6x33quXLl6srukiRIj7v01W/4lpA7BBuZPM6Bzj2v/zyiyah4R4AEB7r0qWL7gOhEWwDVzb2h2NoXle4D+JaeOWVV/S1CxcuaLtxb7S/9pCXAHAOVKpUyfsf4pO0WsyyxGsY3Ttz+/btGK+99NJLOuqxtzDcWVkY3V65ciXGSOeXX37xaFlixGTv3oG14WyFtWjRQtty+vRp22sYcWPU6emQYzQHywXthjVnj73bwlfLMn369MaFCxcctoV1bW85mcASsx9Rjxo1SkehBw4ccNhu4MCBOvo+ceKEw/d764KMzbIEsGSxDfoYzJ49W63iNWvWuLQA//rrL4d9Y9vdu3e7/F7TsgTt27c3smfP7jCSxigZn4fHIrbzbs6cObq/P//80ys3rLNl+dprr+m29r/pxo0beg7AOjItd9OaKFWqlIMl+NFHH7k8hq6sLfyef/75J8Z75nnl77bAu4B+LVu2rIMLHJYqtoOHwPm8wTnljC9uWIQYEiVKZLz++usx3jOv6f3796t1eezYMWP69OlqQWfLls3ByjL7YuvWrW6/C5YRtunfv78+79evn8fPeALtwT4mTpzo9jit8tGydNWv2BcswKeffjqGF8D+fMbxh3ere/fuDtudO3fOyJAhg+113KtMD5Y34D7aq1cvwxcsmQ3rLbCAMCp1JlWqVLa/Meq6dOmS1K1bV0c8+/bt87jfdu3aOYwi8VkAq8ETjRo1chjdlS9fXq0e87MYGa5YsUJat24tuXPntm1XtGhRtZI9gZEarLLXXnvNYdQN4jOVBaM+Z+sGVhCSXGBBmWD0ikxU9JEJEiDQR+gz9LX5QF/g9/75558OlgT0KD5WpYlpQeAYm+2ANQmryL4dDRo00PcxyrcHlmLp0qU9fg9+K0bB9tnXsKRgydr3g/15Bysd341UeLBly5Y4/cYlS5aoxYdRuv3vhvUHi8c5KxjXA6xAX85d/A5Y3Ug2qVq1aoz3zfPK321B5if6FV4Y+0Q5WPM4hrBqnOnVq5fEhytXruj5Z399O1OiRAm9FnCOPv/883ptwiqExWVinnPwHrnDfA+eD/v/Y/uMJ3744Qf1RsA6cyZRPK5/537FvmBR4phjmo0J7gVIwDHPAViG8Ea0b9/e4ZqD1VmjRg3bNYdrA+cCrqGrV696bI95L/EFimUs4KDZX4wmMPXhEsqQIYMKFU58uGkBXDbeuPjsMS8sbw6y82fNz5ufxc0BGXG4AJ1x9Zozhw8f1v9N15+/KFSoUIzXcFE2bNhQXZD2FwsEFEJqcvDgQXU1oZ/tHxBL8zcHAvMiNm8+aAeOvXM7ihcv7rIdrn6zK+Ayx7lkP2jA3xUrVrTt27wRwy2GcABuDvhu8zu8Oe9ccfz4cb15O4NBgfl+fM/dixcv6o3c0znl77aY27vaJ8TSeX847/yVJRrbJAMIEkQA4RgMdnDe2A+E7M85UzRd4SyouBd5+ow31z/6y5+Z2knd9CsGgrhXIbPXvN4gnhBRU5hxzQEMSJ2vu//+97+2aw6GDVy0GHTg+kAmMNzy7qaI4Pj4Kv6MWcaC8wkMMMqBxYATE3FAWHkYtWJkjzk8GEV7wvTFO+PNLJ74fNaf4ERz9Z2w9LztS4C4CCyEbdu2qThAOCGgZqwNoE8xxcPdZGJ7QfEnsHLR36YgoR3lypWTiRMnutw+X758Xv1mZ3ChwxPw448/ymeffaZxNcRTxowZ47Dds88+q/EwTAtBX8HqQpsgtt6cd/4gVM6/QLQFxwEx0PiAaRq4NmIbPOBGbp7fsLZxTiHWunnzZtv3mwOEHTt26LF2Bd4DpvcCAwCAOLq7z/iDRG5Ext21765fMVCAdY1rvkOHDhqrhHjae1PM8xpxS8SPnbEXdXjD0J/wYixbtkzefvttjVMjd8A5Non7uP09xhsolj4CMx+JP0iywUlvAtdlKICqIRDvQ4cOxXjP1WvOmC5eCIVpubkCo3hXrjfn0bonIBJI2jGtKiSn2M9NM9uEUWds7fE3SArA/LZatWrZRu5oB+ZhQsz9XV0JNwgksyCxAslUuOHb3zRw88V7SNhCMpmJOfK2x5e2FShQQPbv3x/jdTOcgPfjC6wADC5xTiVkW8ztsU/TVW6C17zdny/9iZs3zhNv7wcY8CDBDQNGiIZZxAAhEwwGIBLuknwwPxzfh8GS/WcwjzyuST5oOxKkMFfUXbJhpv+z4J0LKfh67ZsDQCRcwfOAewDE0wwtmO0x72veXP/Y/vXXX9cHrg0MGiZMmOAwtx6JZffu3bMNSLyFbtg4jmbtR6/oeFgEodI+nFQYXSED0V4o4aLwBLL4YEkhw9T5YrD/zTgpcRODi80EQgKLyBcQF0WWG24Uc+fOVbc3BNT5glq3bp2OFp1BG5FtZ4LsWLTLXXUTb4C7EzESjJSHDBni0A5caNOmTYvxGYyIMYk8ruCYwSrBDQMPxO7s3biuzjvgqrKMOUndmwo+zZo1k40bN2r/muB3IMsWNy5vYq6egFWBYwrLwVUFGfM3+bstiI/iJjtlyhQtxmCC6wADEsQuvQH96YubGwMsXyrlwKqEmxJuRHsvBQQU+QfI/HQGvwkW0wsvvGBzceIzmGwP9+Qnn3wS4zOw0iAcyOyNLbcAsbxPP/3U7XEqUKCAno/2uQIgLvdADAhxbDBQRKgF15g9uDdgoAUvi6tr2rz/IF8EcXx7cI/CQNf+2ANY8ACZ175Ay9JH0MEYWSGVGentGHVi9BdKhZBQKQQXDKqCILCOmz5OfsSM4O70dGPDxQl3BkZluGAxzQMChHidKVhITIA7EiczLljEDnABY6qDmWjgywWDmC8uNuzPObEIbkfENZDSjpRypH7jJgp3ExJhkPxhulR8nToCSxajThw/tNus4ANLFr/PHLUDjNYh6j179tTEAvQv+hZ9g9fRN64SWLwBo3jEaTFgwG9Dir09uGGYcRizQgyOsSsLxkyNh9DDUsG+cTztK72YDBw4UKeZwCrB+QzBNvsPsbX4uiVNcLNDexHCMKfdYGCDvsZUHBxzf7cFvxsChHMY34sBkDl1BOcGKux4A/oTAxhMFcMUFFiD6E93tGrVSu8JOLe8CRGgnYhF4zyHYJjnHKaq4NxCgpL96zjPfv75Z/1NED978BxxR/QfvF+4ZnC/gqcEfY392ZfgcwZWLCxW/FYMXJA0hfNxxYoV2g78NsTXEVeEIOP+B1HCtLK45A5gcI5cCpyrEDV7b4p53uN+hGsP26Lt8FTg9yBBC9cg7m3oa3h8ILYYVMHiRlgDx9v59yJejHi3T9NGgE+5sxYsSuAKTBGoWbOmpnznzp3bePPNN41ly5bFSKeObYK+p+kEsRUlcMbVRPOVK1calSpVsk3g//LLLzWdHROzvWHt2rU6uTldunQ6baN8+fIxKolgwr1ZWKFixYraB778ZpPr169rX2I77NMVSCEfNGiQUbRoUf2+rFmzasGADz74wKEAga9TR8wHpjUgRR19hikjrqZ8AHzX+++/r+cGJmxj8jyKP4wYMcKIioryalqK87E2Wb58ub6HqQeuqqxgIj0mh6OdSJt/5plntAiDq/1hug1S8/G7vC1KgP3i/KhevbrbQgDOVXNcTRdwBwo9YAoJpkmYxTLQR66KEvizLShegOOK78ycOXOsRQncVZzp0KGDtsmbogT4PTg/cQy8KUoAcO7gmDpPx8K+UMwD5xjahylhKLCAAiHuCm9gChKudxRTwT6TJUumbUYBC2+mlWCK0pAhQ3TKDj6Lyf1t27bVY2OC34BpH2gPrgFMnUORAHdFCWID34XP4dp2B455kyZN9PfgvMA9DQUIUDQGoDAHzqWSJUvq92E7FLTAVBR7MP0IRTGGDh1q+Iola8NaFbjCYB26inMRQvzHqFGjtBAHrjV3iUgk4UF4CslEsL7hMfMFxiwjFMTQ7MFFi7RsrERACAkscPHClQ+3Ogkd4JZHRS1fhRLQsoxQcDIgvle4cGHNUoPfHzEBFB0oVqxYsJtHCCFhBRN8IhQkAyBZApNyMc8JGXpIsqBQEkKI79CyJIQQQjzAmCUhhBDiAYolIYQQ4gHLxSxRxQKVbVDZwd8lywghhIQPiEKi8DxWaPJU9MJyYgmhdC54TQghxLqcPHnS44ozlhNLsyg2Osdc0oYQQoj1uH79uhpP3qwBajmxNF2vEEqKJSGEkERehOSY4EMIIYR4gGJJCCGEeIBiSQghhHiAYkkIIYR4gGJJCCGEeIBiSQghhHiAYkkIIYR4gGJJCCGEeIBiSQghhHiAYkkIIYSEslj++eef0qJFC634jnJDP/30k8fPrF69WipXriwpUqSQokWLyowZMxKkrYQQQqxLUMXy1q1bUqFCBZk8ebJX2x89elSaN28u9evXl23btslrr70mL774oixbtizgbSWEEGJdglpIvWnTpvrwlilTpkihQoVkwoQJ+rxUqVKydu1a+fDDD6VJkyYBbCkhhBArE1arjqxbt04aNWrk8BpEEhamO6Kjo/VhvySLpVixAqMMkdu3g90SQgjxC/cTJ5Zk//4rkiWLyOzZkhCElVieO3dOcuTI4fAankMA79y5I6lSpYrxmbFjx8qIESPEskAojx0LdisIIcQv3EyRQrbnzStFL1yQHJcvS0IRVmIZFwYNGiT9+/ePsdinZSzFS5f+//+JE4tkzRrQphFCSCC5mSyZbMuaVVI9eCCZU6cWyZxZEoqwEsucOXPK+fPnHV7Dcyzi7MqqBMiaxUOsbinmzy+yYEEgWkQIIQnCrfPnJdWpU1K+fHlJliyZJCRhJZa1atWSJUuWOLy2fPlyfd0yscO4WIoYgfXqFb/vJYSQIIG8k+TJk2vYLXv27DrVMKEJqljevHlTDh065DA1BFNCMmfOLPnz51cX6unTp2XWrFn6fs+ePeXTTz+VN998U55//nn5/fffZf78+bJ48WKxXOyQliIhxALcuHFDtm/fLoULF7bNyQ8GQRXLTZs26ZxJEzO22KVLFy02cPbsWTlx4oTtfUwbgTD269dPPvroI8mbN698+eWXoT1txLQozd/hj9ghLUVCiIWEMnXq1GpRBpNEhmEYYiGQ4JMhQwaJiorSWGfAadvW0aIsWJAWISGEeHGv3rFjhwolYpRJkyYNqh6EVcwyLDFjlLAo4TqlRUgIIR45efJkQIXSV4LfAqsA1ystSkIIiRU4OxGXLFmypP4dCkIJuOoIIYSQkCAqKko2btwot2/fliRJkoSMUAKKJSGEkJAQyh07dugUkVCcG0+xJIQQEhJCmTZtWo1RwqoMNULHxo1EMG3kwoVgt4IQQkKWf//9V3bv3i3p0qWTcuXKhaRQAoplIMH8Svu5kYQQQhxInDixiiQyX0NVKAHdsIHEvrQdp4wQQoiNa9euyd69e9WyhFUZykIJKJYJASpPNGwY7FYQQkjICOWOHTu05mu41MWhGzZQMF5JCCFuhRKVc8qWLRvyFqUJLctAwXglIYQ4gPmT4SiUgJZloKxK+3qwjFcSQohg3eEiRYro2sThJJSAYhloqxKF0xmvJIRYmKtXr8rDhw8la9askidPHglH6Ib1N7QqCSHExpUrV2Tnzp1y7ty5sEnmcQXF0t/QqiSEEJtQ7tq1SzJlyiSlS5cO2sLN/oBi6U9oVRJCiM31agplmTJltPhAOMOYpT+hVUkIIbZkHiTyFC1aNOyFEoT/LwgVaFUSQojAorx//76kTJlSihcvHhFCCSLjV4QCtCoJIRbn8uXLOo/y5MmTEmnQDesvWAeWEGJhLl26pKuHZMmSRQrCYIgwaFn6G9aBJYRYWChLly4dMa5Xe2hZ+gPWgSWEWJh79+5pwYFSpUpFpFACiqU/YB1YQogFuXPnjma95s6dW3LlyhXW8yg9EZlDgISG8UpCiMW4ePGibNy4UV2wIJKFElAs/QnjlYQQiwjlnj17JFu2bBqntAJ0wxJCCPGaCxcuyN69e1UoEaOMdIvShJYlIYQQrzAMQ86cOWM5oQS0LAkhhHjk4cOHugZluXLlNOPVSkIJaFkSQgiJlfPnz2syT3R0tAqm1YQSUCwJIYTEKpR79+7V1UOSJ08uVoViSQghJFahzJkzp5QoUcKSFqUJxZIQQojLqjwHDhygUP4fTPAhhBASA7hcK1euLKlTp7a8UAJaloQQQmycO3dO9u3bp9NE0qRJQ6H8PyiW8YVF1AkhEcLZs2dVKCO1GHp8YI/EFxZRJ4REiFDu379fi6IXK1aMFqUTFMv4wiLqhJAw59q1axRKDzDBx1+wiDohJEzJkCGDlq/Lnj07hdINtCwJIcSioM7r1atXVSBz5MhBoYwFiiUhhFiQ06dP6zzKK1euBLspYQHFkhBCLCiUBw8elLx580rhwoWD3ZywgGJJCCEWy3o1hbJIkSJ0vXoJE3wIIcRiyTyFChWS/PnzUyh9gJYlIYRYgAsXLsiDBw+0fF2BAgUolD5CsSSEkAjn5MmTsmfPHhVMEjcoloQQEuFCefjwYXW75sqVK9jNCVsoloQQYgGhRJySrte4Q7EkhJAIhkLpH5gNSwghEcaNGzckXbp0ki9fvmA3JWKgZUkIIRHE8ePHZfPmzXL9+vVgNyWioFgSQkgECeXRo0elYMGCkj59+mA3J6KgG5YQQiKAY8eO6QNCiQfxL7QsCSEkzPn333/l0qVLFMoAQsuSEELCGFTlSZo0qVSuXFkSJ6b9EyjYs4QQEoYYhqHxyU2bNqlgUigDC3uXEELCUCgRn0RCT+7cudWyJIGFYkkIIWEqlFiLEkUHSOChWBJCSBhx584dOXHiBIUygaHtTgghYWJRAiyxVb16dUmVKlWwm2Qpgm5ZTp48WVOdU6ZMKTVq1JCNGzfGuv2kSZOkRIkSeqKglFO/fv3k7t27CdZeQggJVjLPoUOH9G8KpcXEct68edK/f38ZPny4bNmyRSpUqCBNmjRxu+bad999JwMHDtTt9+7dK1999ZXuY/DgwQnedkIISQggjkeOHFHXK0SSBdEtKJYTJ06U7t27S7du3aR06dIyZcoUdTFMnz7d5fZ///231KlTRzp06KDW6OOPPy7t27f3aI0GjBUrsPx4cL6bEGIZocRSW0WLFpW8efMGu0mWxWexrFevnsyaNUuDzPHh3r17Wuy3UaNG/2tM4sT6fN26dS4/U7t2bf2MKY44iZYsWSLNmjVz+z3R0dFaUNj+4TemTPnf36lT+2+/hBAiIufPn1ehLFasGIUy3MSyUqVKMmDAAMmZM6dahevXr4/TF6M008OHDyVHjhwOr+P5uXPnXH4GFuXIkSPlkUcekWTJkkmRIkXksccei9UNO3bsWMmQIYPt4dcla27f/t/fvXr5b7+EECIi2bNnl3LlykmePHmC3RTL47NYIsHmzJkz8vXXX2ts8dFHH1UX6gcffKCjoECyevVqGTNmjHz22Wca41y4cKEsXrxYRo0a5fYzgwYNkqioKNsDozS/kz27SMOG/t8vIcSyrlfcr+Bty5IlS7CbROIas0S1iDZt2sjPP/8sp06dUovv7bffVqutdevW8vvvv3vcR9asWSVJkiQxBBbPYbW6At/RqVMnefHFF3W09dRTT6l4wnpEIWFXpEiRQpeqsX8QQkioCiUyXpHMc+vWrWA3h/grwQexQ2SmTpgwQd0FsOIggk8++aS6amMjefLkUqVKFVm5cqXtNQgenteqVcvlZ27fvh2j/iEE134OEiGEhLNQnj59WooXL65l7EgYFyWA63X27Nnqhj148KC0aNFC5syZo1M+zJTmrl27yhNPPKGu2djAtJEuXbpI1apVdZItXLwYTSE7FnTu3Fl99bAcAb4LGbSIm2JOJk4sWJt43RRNQggJRzCPkkIZQWKJjCwk1jz//PMqitmyZYuxTfny5aVatWoe99WuXTu5ePGiDBs2TJN6KlasKEuXLrUl/cAVYW9JDh06VAUZ/+OkwndDKN99911ffwYhhIQU8M5h6py7MBQJLokMH/2Xa9askbp160q4gqkjyIpF8Dze8UtMWcE8SyT4LFniryYSQiwCbr8Y+OfKlYvesRDXA59jlohRXrt2zeWXNmjQwNfdEUKIZYXywIEDGk5ydU8loYXPYvnHH39oQQFnUJ8VVichhBDvhPLs2bNSsmRJTg+JpJjljh07bAd5z549DoUDUFwAsUZOnCWEEN+EkjHKCBNLJN8guQYPV+5WFPj95JNP/N0+QgiJODD/m0IZoWKJtGaMiLDgKOZX2mfBYs4kMrkYoCaEENfg/mkmlGAhCBKhYlmgQAH9312lHEIIIe6Fct++fTpPHXPEsX4viUCxXLRokTRt2lSLl+Pv2GjZsqW/2kYIIREjlCjliTraFMoIFkvUe0VCD1yt+NsdiGci2YcQQoijRQmhxD2URLBY2rte6YYlhBDvePDggZbwLFWqFIXSavMsA7LEFSGERJhFifnoCF1hwQgKpQXFEllc9erVk2nTpsnVq1cD0ypCCAljody7d69s375d/zYXmCAWE8tNmzbpCiEjR47UeoaIYS5YsECio6MD00JCCAkTzKItWCAChgWF0sJiieWxxo8fryuC/PbbbzrfskePHrpSCFYiIYQQK4J8DgjlpUuXNJnH1YpMxIKLP2PEVL9+fXXHrlixQgoVKiQzZ870b+sIISRMQMGBy5cvS5kyZSiUEUicxfLUqVMybtw4LYMHt2zatGll8uTJ/m0dIYSEgesVj4wZM0rNmjUla9aswW4SCYXFn6dOnSrfffed/PXXX1rbsGPHjvLzzz/bKvwQQojVXK9p0qRR7xpKf5LIxGexHD16tLRv314+/vhjqVChQmBaRQghYSKUcL0i2ZFENj6LJRJ7mOFFCLG6UO7evVuuXLkiZcuW5XqUFiCpt2tZ4oRInDix7Ny5M9Zty5cv76+2EUJISILiLJhnXq5cOcmcOXOwm0NCRSyRxGPWhjXXtURA28R8ztqwhBArkC9fPsmUKZOkT58+2E0hoSSWWMvSTIXG34QQYkXX6/79+yVv3rySLl06CqXF8Eos7TNdjx8/LrVr15akSZPGKBj8999/MyuWEBKRQrlr1y65du2aFmAh1sPneZYoRICgtjNRUVH6HiGERKpQMkZpXXwWS3eFgZE+jblGhBASSaAouimUiFMSa+L11JE2bdro/xDKrl27SooUKWzvIakHGbNwzxJCSKQl8+TOnZtCaXG8FssMGTLYLEsEt1OlSmV7D1UrUOape/fugWklIYQkIDAAMD0kf/78TOQhvonl119/rf9j2ZkBAwbQ5UoIiVihxHxyFEZHnVfUvSbE5wo+w4cPD0xLCCEkRITyxo0bWmCFQkl8EsvKlSvLypUr1WeP9SxjK3e3ZcsWb3ZJCCEhl/VqCiWSebCKCCE+iWWrVq1sCT2tW7f25iOEEBJWwAhAfBKrh5g5GoSYJDLs69ZZAMQhcCFgXmi8A/fNmolcuCCSPbvIkiX+aiIhJIFdr7gvMNvVelz3QQ98nmeJDDEs/GyyceNGee211+SLL76IW2sJISRIoPIYpr1hBRH8TYjfxLJDhw6yatUq/RvF1Rs1aqSCOWTIEBk5cqSvuyOEkKAAcUSM8ubNm5rM41zCk5B4iSXKPlWvXl3/nj9/vgbCURP222+/lRkzZvi6O0IICZpFCaHEIvacS0n8Lpb379+3JfusWLFCWrZsqX+XLFlSzp496+vuCCEkKHFKpGtQKEnAxLJMmTIyZcoUWbNmjSxfvlyeeOIJff3MmTNcLZwQEvIWpTngx5Q4CiUJmFi+//77MnXqVHnsscekffv2OjIDixYtsrlnCSEklJN53C0IQYg7fI5oQyQvXboUI9W6R48ekjp1al93RwghCSKU27dvlzt37ugAn0JJfCVO6V9JkiSJMScJNWMJISTUgNsVFqUplFgIgpCAu2HPnz8vnTp10iVrkGoN4bR/EEJIKIG1KO/evUuhJAlrWWItyxMnTsjbb78tuXLlojuDEBKytV4TJ04s2bJlU08Y51GS+ODz2bN27VrNhK1YsWK8vpgQQgLpekWMMkeOHLp4M4WSJLgbFieexcrJEkLCUCijo6NZ75UETywnTZokAwcOlGPHjvmvFYQQ4mehRIyS61ESf+Gzb6Jdu3Zy+/ZtKVKkiE4VSZYsmcP7V65c8VvjCCHEF44ePapCiTBRmjRpgt0cYmWxhGVJCCGhCAbxefPm5ZxvEnyx7NKli/9bQQghceTevXuyd+9eKVq0qFqTFEoSEjFLcPjwYRk6dKiWu7uAxY9F5LffftMyUoQQkpBCiRjlrVu3gt0UEuH4LJZ//PGHLsu1YcMGWbhwoS5xA3DCDh8+PBBtJIQQt0KJpB7GKEnIiSUyYUePHq0rjiRPntz2eoMGDWT9+vX+bh8hhMQA09ewcLMplHS9kpCLWeIE/e6772K8nj17di2wTgghgQaVw5DMgwE7hZKEpGWZMWNGl4s8b926VfLkyeOvdhFCSAwwLeTIkSNqWeJeRKEkISuWzz33nLz11lty7tw5Hd2h/uJff/0lAwYMkM6dOwemlYQQywOhRIwSizkgXklISIvlmDFjpGTJklr2Dsk9pUuXlkcffVRq166tGbKEEBIIody2bZs8fPhQY5QpUqQIdpOIxfA5ZokYwbRp02TYsGEav4RgVqpUSYoVKxaYFhJCLA2SeCCU8GJBKFOlShXsJhELEudS/LAs8cAK5FgrjhBCAgFWDMEyW1gSkEJJQt4N+8svv8iMGTMcXnv33Xe1UDEC7Y8//rhcvXo1EG0khFgQDMJxT0FuROHChSmUJDzEcuLEiQ5VMv7++291xWIR6Pnz58vJkydl1KhRgWonIcRiQgnX68GDB7kkIAkvsUQpOyTxmCxYsEAaN24sQ4YMkTZt2siECRPU+iSEEH8IJShfvrxaloSEjVjeuHFDsmTJYnu+du1aadiwoe15mTJl5MyZMz43YPLkyVKwYEFJmTKl1KhRQzZu3Bjr9teuXZPevXtr/AIZccWLF5clS5b4/L2EkNAWSiTz4L5ASFiJJQoOoLI/QAYs5jvZW5qXL1/2eYLwvHnzpH///lpTdsuWLbpYa5MmTWzF2Z3B3CpYs1h4Gpbt/v37NTOXxRAIiQzgcoVAUihJ2GbDPvPMM/Laa6/J4MGD1ZLLmTOn1KxZ0/b+pk2bpESJEj59OeKg3bt3l27duunzKVOmyOLFi2X69Olag9YZvI7FpREvNRedhlVKCAl/ixJZr0jigVASEraWJZJ5qlWrJq+++qq6Sb755htJkiSJ7f05c+ZIixYtvP5iWImbN2+WRo0a/a8xiRPr83Xr1rn8zKJFi6RWrVrqhs2RI4eULVtWiyRgonJsk5mvX7/u8CCEhA537tzRcpkHDhwIdlMIib9liRHfrFmz3L6/atUq8QUUXYfIQfTswfN9+/a5/AxqQv7+++/SsWNHtW4PHTokL7/8sk5adrc82NixY2XEiBE+tY0QknBCicE3BsoojE5IRC3+HCxQwQOrm3zxxRdSpUoVadeunWbjwn3rjkGDBklUVJTtgSkuhJDQEkqWsCMRW8EnvmTNmlXduCiKbA+eIx7qCmTAIlZp7/4tVaqUFnWHW9d+fU0TXIC8CAkJPZDZjmsZiX28RkmoEzTLEsIG63DlypUOliOeIy7pijp16qjrFduZIM4BEXUllISQ0AMlMgGuW9wDKJQkHAiqGxbTRjD1Y+bMmTotpVevXlolyMyOxZJfcKOa4H1kw/bt21dFEpmzSPBBwg8hJPS5ffu2zqWGNwjYe4kICWWC5oYFiDlevHhRM21x8SBusXTpUlvSz4kTJzSeYYLC7cuWLZN+/fppZQ/Mr4RwYn1NQkjoCyVilJgikjlz5mA3hxCfSGTEofAiFnuuWrWquk/s/w4HMHUkQ4YMmuyTPn36+O2sWTMRFFDInl2EVYQI8UooMShm2ISEmx7EyQ3btGlTOX36dIy/CSHE3bQvJOdRKIml3LD2xihXBCCEuAP3BxRCL1mypCbmUShJuBJW8ywJIeEDkvVQ8xnzKeF+pVCScIZiSQgJiFAiRglrEkJJSLjDs5gQEhChRNIfCg6Yix4QEs7QsiSE+A1Ykjt27KBQkoiDliUhxG9gXjRKUKZJk4ZCSSIKWpaEkHiDBeFRihLZrxkzZqRQkogjTpbl1KlTbVV27P8mhFhTKBGjxDJ+WHaPCT0kEonTWd2hQweXfxNCrMWNGzdk+/btKpQoQUmhJJEKz2xCSJzA/ElTKJHMQ6EkkQzPbkJInEiZMqXkzZtXHxRKEunwDCeE+Fx8GlNEkMhTsGDBYDeHkASBYkkI8UkoMY8yXbp0uloD6r4SYgXiNXXk7t27/msJISTkhRIxytSpU0uZMmUolMRS+CyWcL+MGjVKF15OmzatLr0D3n77bfnqq68C0UZCSIgIJa55Zr0SK+KzWI4ePVpmzJgh48aNc1hFoGzZsvLll1/6u32EkBAgSZIkkjlzZilXrhyFklgSn8Vy1qxZ8sUXX0jHjh31AjJB6vi+ffv83T5CSJDnUaLQAMrXwfVKoSRWxWexPH36tBQtWtSle/b+/fv+ahchJMhERUVpZZ5jx44FuymEhJ9Yli5dWtasWRPj9QULFkilSpX81S5CSBC5du2aLeuV00MIicPUkWHDhkmXLl3UwoQ1uXDhQtm/f7+6Z3/99dfAtJIQkqBCuXPnThVKxCjtwy2EWBWfLctWrVrJL7/8IitWrNA4BsRz7969+lrjxo0D00pCSIJmvlIoCXEkTtH6unXryvLly+PyUUJIiHLv3j3NcM+fP7+WsMPalISQ/4/PV0PhwoXl8uXLLl03eI8QEn5cvXpVNmzYYLu2KZSEOOLzFYHMOKSSOxMdHa1xTEJI+AklYpTp06fXeq+EkHi4YRctWmT7e9myZVoX0gTiuXLlSmbNERKmQgmRxDxKxigJiadYtm7dWv9HPUhkw9qTLFkyFcoJEyZ4uztCSJAxDEOOHj2qQokKXHS9EuIHscQ0EVCoUCH5559/JGvWrN5+lBASgkKJga+Z8UqhJCR2fL5CMBKlUBISvly5ckU2bdqkeQbwClEoCQnQ1JFbt27JH3/8ISdOnNB0c3teffXVuOySEJJAQrlr1y7JlCmTCiUhJEBiuXXrVmnWrJncvn1bRRMrEVy6dEnXuMuePTvFkpAQBdNCdu/erUKJZB5alIR4j89XS79+/aRFixaaRZcqVSpZv369HD9+XKpUqSIffPCBr7sjhCQAWORgz549OrilUBLiOz5fMViF4PXXX9eLDYkBiHvky5dP17ccPHhwHJpACAk0cLli0WYshEChJMR3fL5q7BMC4HZF3BJg3uXJkyfj0ARCSKBAiOTw4cOa/YprlEJJSALFLLEMF6aOFCtWTOrVq6eF1HFBzp49W+dqEUJCA1yXiFFmyZIl2E0hJOzxeZg5ZswYyZUrl/797rvvarJAr1695OLFizJ16tRAtJEQEkehxDQvuF4xp5IQkoCWZdWqVW1/ww27dOnSeHw9IcTfREVF2YSyVKlSdL0S4gf8dhVt2bJFnnzySX/tjhASR7AWJVYAYjIPIf7DpysJBdQHDBigWa9HjhzR1/bt26d1Y6tVq2YriWcJVqwQuXAh2K0gxAZCIVi4GQKJDHW6XgkJglh+9dVX0rRpU5kxY4a8//77UrNmTfnmm2+kVq1akjNnTq0KsmTJErEMU6b87+/UqYPZEkLkwoULOo/y7NmzwW4KIdYWy48++khFEokD8+fP1/8/++wzXd5nypQpGhuxFLdv/+/vXr2C2RJicSCUe/fulWzZsknx4sWD3RxCrJ3gg7lazzzzjP7dpk0bSZo0qYwfP17y5s0rliZ7dpGGDYPdCmJxoUSyXcmSJel6JSTYYnnnzh2t/wpwQaZIkcI2hYQQEhxQcjJ37txStGhRCiUhoTJ15Msvv5S0adPq3w8ePND4pfNyXSykTkjgQW1mVORB5isehJDAkshAHSwvKFiwoMeRK943s2RDFWQL4iaDuWjp06eP+46aNfv/2bBww1opsYkEnfPnz6vrFdak5cMghCSQHnhtWR47diw+bSKE+IFz587pdC1koOfJkyfYzSHEMsRp8WdCSPCEErkCyHpljJKQhIPlPQgJE7DgOoWSkOBAy5KQEOfu3buSMmVKKVSokD6nUBKS8NCyJCSEQUWeDRs2aCICRJJCSUhwoFgSEqKcOXNG9u/fr65XTg8hJAzFEtV8hg4dKu3bt9cKIuC3337TZYEIIf4RygMHDmjGKxZap0VJSJiJ5R9//CHlypVT19DChQvl5s2b+vr27dtl+PDhgWgjIZYCq/ecOnVKhZKVeQgJU7EcOHCgjB49WpYvXy7Jkye3vd6gQQNZv369v9tHiOWEEktsVapUiUJJSDiLJVYZeeqpp2K8jkLOWImEEBI3Tp8+LZs3b9ZSksmSJaNQEhLOYpkxY0aXa+Zt3bqVFUUIiYdQHjx4UDJlyiRJkiQJdnMIIfEVy+eee07eeustrSaCkS/cRn/99ZcMGDBAOnfu7OvuCLE8iE9CKFHntUiRIrQoCYkEsRwzZoyum5cvXz5N7ildurQ8+uijUrt2bc2QJYT4VpXn0KFDej1RKAmJgFVHnDlx4oTs2rVLBRPJCEhvDwe46ggJNW7cuKFL31EoCQldPfDZsly7dq3+nz9/fmnWrJk8++yz8RbKyZMn6xJgKOlVo0YN2bhxo1efmzt3rt5gWrduHa/vJyShOXnypBw9elQwVkXBAQolIaGNz2KJKSKoUTl48GDZs2dPvBswb9486d+/v87R3LJli1SoUEGaNGliK3YQ25JhiJPWrVs33m0gJKGFEoU94ujUIYSEg1iissjrr7+uxQnKli0rFStWlPHjx2uSQlyYOHGidO/eXbp166bxzylTpkjq1Kll+vTpbj/z8OFD6dixo4wYMUIKFy4cp+8lJBggfAGhhGcGg05alIREqFhmzZpV+vTpoxmwuOifeeYZmTlzprpRYXX6wr1793ReWaNGjf7XoMSJ9fm6devcfm7kyJE6r/OFF17w+B3R0dHql7Z/EBIM4C05cuSIFChQgEJJiJUKqeOCR0Wf9957T0vgwdr0BRQxgJWYI0cOh9fxHFNT3MVMv/rqK5k2bZpX3zF27FgN4JoPZB0SEgyyZMmimeQYWFIoCbGIWMKyfPnll3VFhA4dOqhLdvHixRLorMFOnTqpUMLC9YZBgwZpppP5QLyIkIQE5xyyxlFsIGfOnBRKQqyw+DPEB1moiF02btxYPvroI2nVqpXGGX0FgocbyPnz5x1ex3PcVJyB2xeJPS1atLC9hqII+kOSJtXljDBXzZ4UKVLog5BgcPz4cc16RWwd00MIIRYRyz///FPeeOMNnTLirXXnDhRir1KliqxcudI2/QPih+eIizoDFxZq09qDQgiwOCHadLGSUAIDOzzgdkVCDyHEQmIJ96s/wbSRLl26SNWqVaV69eoyadIkuXXrlmbHApTQQ81ZxB4xDxPuXudatcD5dUKCnfUKoURcHwk9hBALiOWiRYukadOmuhIC/o6Nli1b+tSAdu3aycWLF2XYsGGa1IOpKEuXLrUl/eCmgwxZQsIJJJMhJEBvByEWKncHsYKQYbpGbMKFxAVkt4YyLHdHAgUuJQz8EJ7gAI+Q0McXPfDKsjSTaJz/JoT8TyjhdkVCD0IC8Y3nE0JCC5+Hv7NmzdKJ/q4KDOA9QqwGhBIZrxBKuF4plIREHj6LJRJvYLI6g4xUMymHEKsJJWLrjFESErkkjsvNwdWkatSGhe+XEKuBOD2FkpDIxuupI1izEiKJR8OGDbUIgP3NAqPrJ554IlDtJCSkwKARCzenSZNGihYtyqo8hEQ4XoulWTRg27ZtuoSWfTUSFBfAxOunn346MK0kJMSEEgXR4U3B+quY/0sIiWy8FkusNwkgipgbyRsEsapQouwihBIWJa8DQqyBzxV8UG2HEKsLZbFixbSyFCHEGngllpkzZ5YDBw5oSnymTJlijc9cuXLFn+0jJGR48OCBLitHoSTEengllh9++KGkS5fO9jeTGYjVLEoksaHcY7Vq1XSlHEKItUjqq+u1a9eugWwPISEnlIcOHdKyWMgIp1ASYk18nme5ZcsWh2Wyfv75Z82UHTx4sFbxISSShPLgwYNy+vRpXeSc9V4JsS4+X/0vvfSSxi8B0ueRGYuFn7///nt58803A9FGQoImlFjkvESJEpI7d+5gN4kQEk5iCaHEMloAAlmvXj357rvvZMaMGfLDDz8Eoo2EJDgo6WgKJaxKQoi1SRqXEbe58siKFSvkySef1L9R6guZgoSEM2Y5RywqjsXI4TUhhBCfLcuqVavK6NGjZfbs2fLHH39I8+bN9XWUuzMXbCYkXIUSnhMURQcUSkJInMVy0qRJmuTTp08fGTJkiFYxAQsWLJDatWv7ujtCQkooz549q+UbCSEkXm7Y8uXLO2TDmowfP55p9SRshXL//v1y7tw5KVmypOTMmTPYTSKEhLtYmmzevFn27t2rf5cuXVoqV67sz3YRkmCcPHlShbJUqVIMJRBC/COWFy5c0OkiiFciCQJcu3ZN6tevL3PnzpVs2bL5uktCggqmhWCprSxZsgS7KYSQSIlZvvLKK3Lz5k3ZvXu31oHFY9euXVrh5NVXXw1MKwkJUGUerEmJtVkplIQQv1qWS5cu1SkjcFmZwA07efJkefzxx33dHSFBEcp9+/aplyRDhgzMeiWE+F8sMccSBaWdwWvm/EtCQlkoEWu/ePGiDvgYNiCEBMQN26BBA+nbt69WNzFB7cx+/fpJw4YNfd0dIQkKsl4hlPCGZM+ePdjNIYREqlh++umnGp8sWLCgFClSRB+FChXS1z755JPAtJIQP4FsVwglLUpCSEDdsChrh6IEK1eutE0dgTurUaNGvu6KkAQB4QEUG0DWKxYvJ4SQgIrlvHnzZNGiRboUF1yuyIwlJNSFEoM61C3GAubp06cPdpMIIZEslp9//rn07t1bihUrJqlSpZKFCxfK4cOHtXIPIaEulGXKlKFQEkICH7NErHL48OGaILFt2zaZOXOmfPbZZ3H/ZkICLJR79uyxCWXWrFmD3SRCiBXEEgs9d+nSxfa8Q4cO8uDBA40FERJqYJktTGeiUBJCEtQNGx0drSXBTBInTqyrM9y5c8cvDSHEXxblrVu3ND6JhZsJISTBE3zefvtth2onSPR59913tQqKycSJE/3SMELiIpQowxgVFSU1a9bUMnaEEOIPvL6bPProoxqvtAfrV8I9a+/6IiSYQnn16lUpW7YshZIQ4le8vqOsXr3av99MSICEMnPmzMFuEiHE6hV8CAk1EA5AnJJCSQgJFPRVkbC2KPFImTKlVK9eXZPOCCEkEPDuQsISiCTWUYX7FSuJUCgJIYGEdxgSdjx8+FB27twp165dk/z58zOxjBAScCiWJOyEEhYlpoeUK1eOhdEJIaErlmvWrJH//Oc/UqtWLV3LEsyePVvWrl3r7/YR4sDly5dVKMuXL0+hJISErlj+8MMP0qRJEy2mvnXrVq3sA3ADGzNmTCDaSIjGJQEWbK5Ro4ZkzJgx2E0ihFgIn8Vy9OjRMmXKFJk2bZrW3jSpU6eOrnNJSCBcr9u3b5czZ87o8xQpUgS7SYQQi+GzWKKKD6r5OIOSd0i4ICQQyTw3btxwKLVICCEhLZY5c+aUQ4cOxXgd8crChQv7q12EOAglYpR0vRJCwkYsu3fvLn379pUNGzZoyj5cY99++60MGDBAevXqFZhWEkuCusOmUNoX6yeEkJCv4DNw4ECdEN6wYUO5ffu2umQRQ4JYvvLKK4FpJbEkBQsWVE8GltsihJCwEktYk0OGDJE33nhD3bE3b96U0qVLS9q0aQPTQmIpsKD4gQMH1KWPMnb2SWSEEBJ2tWGx8DNEkhB/CuWOHTu0KHrevHlVLAkhJCzFsn79+rGWF/v999/j2yZiYaGEa79ChQqSPn36YDeJEELiLpYVK1Z0eH7//n3Ztm2bliDr0qWLr7sjRAsO4PyBUCKZh0JJCAl7sfzwww9dvv7OO+9o/JIQX4GnIl++fOraZzIPISSiC6mjVuz06dP9tTtiEdfryZMn1bLMkiULhZIQEvliuW7dOiZkEJ+EEiXsjh8/bqsvTAghEeOGbdOmjcNzWAVnz56VTZs2ydtvv+3PtpEIBXFuJPPcuXNHk3k4yCKERJxYOldSwQr1JUqUkJEjR8rjjz/uz7aRCM56hVAiWYzzcwkh4UBSX2t1duvWjYvukjiDwRUEEgMsCiUhJCJjlkmSJFHrkauLkLi4Xq9fv27zRFAoCSERneBTtmxZLXBNiC9CiWSePXv2aF1hQgixxOLPKJr+66+/amIPrAX7ByGuilYg4xXue1iWhBASbnh950ICD2p2NmvWTK2Eli1bav1OxC7xwFqDcY1jTp48WVeYQFZkjRo1ZOPGjW63nTZtmtStW9f2vY0aNYp1exI87t27p0KJ/5HMkyZNmmA3iRBCApvgM2LECOnZs6esWrVK/Mm8efOkf//+MmXKFBXKSZMmSZMmTWT//v2SPXv2GNuvXr1a2rdvL7Vr11Zxff/99zWOunv3bsmTJ49f20bib1UCCiUhJNxJZGCipBfAfXbu3DmXAhYfIJDVqlWTTz/9VJ8jpoXSZ1gbE2tnepOhCwsTn+/cubPH7eEqxvSXqKio+NUgbdZM5MIFEfTHkiVx308EAksSyWB44PSKrfA+IYQEC1/0wKcAkr9veripbt68WV2ptgYlTqzPURHIG1B8GxZM5syZXb6PWBnjqgnvesWalIBCSQix3DzL4sWLe7z5Xblyxev9Xbp0SS3DHDlyOLyO5/v27fNqH2+99Zbkzp3bQXDtGTt2rLqQScIJJQoPFChQINjNIYSQ4IglRMe5gk8wee+992Tu3Lkax3RXMm3QoEEaEzWBZQk3L/EvsOCR+AWhRIwyderUwW4SIYQERyyfe+45v8Yss2bNqnGt8+fPO7yO5zlz5oz1sx988IGK5YoVK3QNRHekSJFCHySwwEtAoSSERCpexywDEXvC+oVVqlSRlStX2l5Dgg+e16pVy+3nxo0bJ6NGjZKlS5dK1apV/d4u4j1mkQG4wpGoRaEkhFhaLL1MmvUZuEgxd3LmzJmyd+9e6dWrl87nRA1agAxXuFJNMFUEq5tg7UzMzUSGLh5ceDo4rlesNnPhwgUdTCVLlizYTSKEkOC6YQNVpqxdu3Zy8eJFGTZsmIoe3HiwGM2knxMnTjhUffn88881kaRt27YO+xk+fLi88847AWkjcS2USObBecFFmwkhkY7X8ywjBc6z9K9QYnCTKlWqYDeJEEJCZ54lIeDgwYPqlqdQEkKsgs+LPxOC+bawKt1N1yGEkEiDliXxirt378qOHTvUBYssZgolIcRK0LIkXgklYpTAYiFuQghRaFkSr4USMUpalIQQK0KxJG5BXBIl7ACFkhBiZeiGJW7B/NYiRYroPEqWDCSEWBlaliQGd+7ckePHj2t8EvV7KZSEEKtDsSQxhBIxSlRTwvJphBBCKJbEhVDC/YoYZdKk9NITQgjg3ZA4ZL1iybQKFSrQ9UoIIXZQLImCQgOIT+bPn59CSQghTlAsLc7t27c1NomM12LFigW7OYQQEpIwZmlxoYTr9dChQ6zMQwghsUDL0qJggW0UHMCCzWXKlNHFmwkhhLiGlqXFhRLJPIhXEkIIcQ8tS4uWscM6lLAoKZSEEOIZWpYWm0cJoUQyD+ZRUigJIcQ7KJYWcr1u2bJFjh49qs8ZoySEEO+hG9YC3Lx5U2OUmD+JeZSEEEJ8g5alhYQSyTxI6iGEEOIbFMsI5+LFixRKQgiJJ3TDRiioyoM6rwULFlTXK/4mhBASN2hZRiA3btyQ9evXy5UrVzSRh0JJCCHxg2IZgUKJGGXKlCklffr0wW4OIYREBHTDRqBQpk6dWsqXL8/1KAkhxE/QsowQUAj9wIEDFEpCCAkAvKNGiFAiNlm2bFmNT1IoCSHEv9CyDHOuX7+uy2zdv39fp4hQKAkhxP9QLMNcKBGjBCxfRwghgYNmSJgSFRUlO3bskLRp00q5cuVoURJCSAChZRmGwOW6c+dOCiUhhCQQvMuGIShbV7JkScmUKRMLDhBCSAJAyzLMXK8nTpzQv7NmzUqhJISQBIJiGSZcu3ZNY5QoYYcFnAkhhCQcFMswEUrEKNOlS6cxysSJedgIISQh4V03DErYwaJEnVcIJV2vhBCS8DDBJ8RB+bq8efNKgQIFKJSEEBIkaFmGKFevXpVbt26pQBYuXJhCSQghQYRiGaJCiRilmflKCCEkuFAsQ1QoM2bMKCVKlAh2cwghhDBmGVpgWsiuXbtUKLGCCLNeCSEkNKBYhhAQxyxZskipUqUolIQQEkJQLENkegjqvMKixIMQQkhoQfMlyFy+fFm2bt0qp06dCnZTCCGEuIFiGWShRIwyc+bMkidPnmA3hxBCiBsolkEWSsQoS5cuzRglIYSEMLxDBzHzlUJJCCHhARN8grBwM9ajLFq0qBiGQaGMEHAsHzx4IA8fPgx2Uwgh/wcqnyVNmlQSJUok8YVimYBcunRJ9u7dKxUqVNDC6P44gCT43Lt3T86ePSu3b98OdlMIIS7qa+fKlUuSJ08u8YFimUBcvHhR9uzZo4s2Y5oIiQywtujRo0d1BJs7d269IDkIIiQ0vD0YyOLei2u0WLFi8fLkUSwTUCizZcumBQd4M40ccDFCMPPly6cjWEJI6JAqVSoNex0/flyv1ZQpU8Z5XwyYBRjcSI8cOUKhjHAYeyYksq9NWpYBxEzgqVixIt1zhBASxnA4HCAuXLiglXmQIZkiRQoKJSGEhDEUywAJJbJe4S/nos2ExJ8ZM2aEdN3kr776Sh5//PFgN8NS7NmzR/LmzSu3bt1KkO+jWPqZ8+fP60HMnj27lCxZkhYlCUm6du2q5yYeCBFg3u/IkSPVE+KNcJmfdfc4duyYBBu0AW3BtYjFCuxBaOSdd96xPX/sscd027lz5zpsN2nSJClYsGCs33P37l15++23Zfjw4THeQ81n9C+W3HPXvm3btsV4D+157bXXHF6Dp+qZZ56RHDlyaKIKsju7d+8uBw4ckECGkoYNG6ZTLzD4b9SokRw8eDDWz6Cv0fYCBQroZ2rXri3//PNPjPskzkFkkCMx7oknnoixX/OY2D969uxpex8FXWrWrCkTJ06UhIBi6Ufu3Lkj+/btk5w5c1IoSciDGxTmh+Im9frrr6t4jB8/3uPn2rVrp58zH7Vq1dKbtv1ryA72FmQpBhLcvD/44AOP20GAhg4dqoVDfGHBggU6b7pOnTouBxbPPvusXL9+XTZs2CBx5ddff1VhiI6Olm+//VY9V998841kyJBBhTpQjBs3Tj7++GOZMmWKtj9NmjTSpEkTHSC448UXX5Tly5fL7NmzdSF7WNwQ2dOnT9sEuHXr1pr4+PPPP+sgAMKKbZytROfzCu2xp1u3bvL55597NciLLxRLP4JRVLly5aREiRIUShLyIJaOgR1uVL169dKb1aJFi/SGhZs/RMCen376SW+WuDHhc+YDlhOsA/M5xK9NmzY6nxj7gVjAkjCBKMOy+/LLL6VQoUK2dP5r167JSy+9ZLOcYI1BJOxZtmyZZpVj36bYe+KVV15R6wPhkdho3769tmHatGk+9SOs0RYtWsR4HaLw9ddfS6dOnaRDhw7qqo0LKHYBUWjWrJkeHxwn9FuNGjV0EDB16lQJBGg/LGsMIFq1aiXly5eXWbNmyZkzZ/RccGcw/PDDDypqjz76qHoscLzxP0QNYHC2fv16fV6tWjW9X+JvfHbOnDkO+7M/r/DA+WRP48aNtXToH3/8IYEmJLJhJ0+erCPac+fOaXWbTz75RKpXr+52+++//15HU3BjwBXx/vvv64kULNBu3EDgP8cKIoRIp06olp+w35kli8js2fEa7KHAPwTxueee0xt927Ztbe+bz9OlSxfrVCncWCFmuIHhuujdu7dao6tXr7Ztd+jQIb2pLly4UOP6+FzTpk3VCoTFVKRIEQ1n2Mf8IRoQB1gsyDL/z3/+IwMGDFBLy5MIwtKBm/nTTz91ux1uxEOGDNHtunTpov3gDWvXrlVBdGbVqlXaZogbVhWCO/LDDz/0er/2AwRU/3rzzTddvh9bLBduS/RnbNy8edPl65jIj3sb2m8CSxYivW7dOj1HnDFLPjrPZ8S5hX4CsI6B/TY4nhi8YRtYpiY4tmg/hBIDEtz37eczY6CGgdeaNWukYcOGEtFiOW/ePOnfv7+a+TgIGMnAzN+/f7/GGpz5+++/9eQfO3asPPnkk/Ldd9+pSb9lyxaXcYFAcy51anW9wqePkRgtSqJAKD1YMqECztuVK1fqTRlWGMANCzd3WG44t2GVLVmyRFasWBHrvrAfuN5wozVdsbBGypQpo3ErWBIA1idex/xj8N///lc2btyo7sXixYvra4ULF3bYN9yjuE9ASEGfPn1U2DyBa/K9997Tm22/fv1sn3fFyy+/LB999JFaot64N2GJRkVFaezNGViSEBQIPu5N+D0Y6CNW5wtmLA+hHV9B/2BAERcglACWvj14br7nDAZScMuPGjVKPQDYFtYixBXWpfk78ufPL4MGDVKrGIMHDCIQ37X3FMAah9cDfbtjxw556623VBcwwLIH76PoQKAJuljipIRfGm4GgIth8eLFMn36dBk4cGCM7XEiw/3yxhtv6HMcFIwaMWLEZxOSc+nTy75MmfRmggucQkkcrLwQ/064OGEBQoRg2eHmZCa9wLMDgZs5c6Zehxjd48YF11psQOwgkvYxSyRiwPrBe6ZYYl+mUAIkucAzYwqlK2BR2AudKeLegAH4I488ogKIAbY7YN1AYDBogGvaE3AdAmdLCiKKm7ppTQFYwhBQX8USg5m4AoPDldERSGbPni3PP/+8WtMYKFSuXFkNnM2bN+v7qKiDvnnhhRfUE4dtYL3Cs2D/W3v06GH7G+EtHG9Yj4cPH3Y4D2C1JkRd5qCKJUaX6ECMMOzNcXQcRiKuwOuwRJ0vBHc+dJj8ptkPEGj3B5dSppR9GTNKrlu3KJQkJvFwhyYU9evX11gRXFkYnWN1BntgXSJEArGECxYDWn+d586uSNzwPIGbrD1oiy9CAusSVo850HYHRA3u3tGjR3vMhMUye2jH1atXHV6HICMJBt4yE7QVgxJkr+KeYcbfYJk6A7GFyxOYAwh4sNB+X4iPGxauT4B4c65cuWyv4zlcn+6AkMEFj9g37rf4LNzw9p6CKlWq6AAJvx06gIET+qpq1apu92v2JVz49mKJmGVs3oKISPCBHx7+bV/MfLzuy/Zw1+KkMx++ZOnFRsboaCly8aIUv3aNQknCEggWXGNwiTkLpSkacG8hGxLxQ8TxPAHX28mTJ/Vhgs/i5g8L0x1IHoEbLpDTIGAtI/HIlcfKHgzYcd/AQMLTFBgMNPC78BvtgQWJDGMIgvnYvn271K1bV71mAFYVFlYwLS4TCAwEwRRJZJNiO+dMUBP0rTtgJdu3wdXDHUgigmDCtW5iZvV6I9o4vyCUGEjAxY9YtjO4J0Mo4WretGmTy21MzLbaCzfYtWuXVKpUSSLeDRtoYLXaW6I42P4QzKSZM0s+xKWC4W4jJAHIlCmTigssMdyw4Sb1BLxCcJl17NhR8w+Q8IE4YL169WK1GvA+XLxPP/20hmYg4rCkMBBF2MVfvPvuu+pedjU4sKd58+ZqySCm5jw4dwaeLbhbzXmRuKkjhwLJKc5xRrgjIWCwWtEG3JvGjBmj34GpIUiwQmgJAoK+N0UHmcOYY9myZUt59dVXtX9gbMyfP19OnDgRY36oP9yw6Hv8JrS1WLFiKp5wY8MLgTwRE7hGn3rqKY0hAwgjrGhkuUL0cf6gH8xQG0DsFr8RAzXEuPv27av7NAs7wNUK6xyJm7DeEbNEvBnnCAZWJhjMYEqKfRJSRFqWGC3BX22fVg7w3HQBOIPXfdkeMQi4O+wffnOzLVkSFu42QuIK4kpwkyEG5e0NFnPnILS4seEmBvcbEvk8gexYxDQhKLDWkP3p78W0Ya3ht8Q2T9AEWfbebIc+QvKT6U6FVYn2u0rIgaiYyVIAvxHFDPBdEAEMFiCOyKS1d03D4kJyI1zRiC1j3+gnfCfELFCgfYjf9ujRQ48NXLZLly51iNFC2CDcJmgTMqDRxs6dO2usGAJq70ZHIg8yiLENxB9/208bgcWOZDKIJ7aBlY6++eWXXxzah89gG8TAA44RZKpXr2706dPH9vzhw4dGnjx5jLFjx7rc/tlnnzWefPJJh9dq1aplvPTSS159X1RUFIIc+j8h8eXOnTvGnj179P9IZNasWUaWLFmM6OjoYDclpGnbtq0xZsyYYDfDUkRHRxv58+c31q5dG+dr1Bc9CHpRArghMAkYWXfIlkMGGgLDpsmOkYl9AhDMdYxsJkyYoG4aZO/B1226AAgh8QfZhbAYkBSDQgHxXWU+0sE8cS7qnrDA/Tx48GCXlZMiMmaJLCksjoz6g0jSQZYVxNCME6BD7Ncjw9wv+LJRVQIdBV86MmGDMceSkEgFySSI78GVaj9YJa5B1qw5R5UkDIjbmnM3E4JEMC/FQiDBBxlY8Kv7LX5JLAtiWpiAb1+2jRASHteoL3oQdDcsIYQQEupQLAnxAxZz0BBiuWuTYklIPDDT4ROi3BYhxHfMa9O5AlTYJfgQEs5gnjDqnpo1SlG/lBWdCAkNixJCiWsT16j9CjZxgWJJSDwxC2J4W9SbEJJwQCjdFa3xBYolIfEEliTqVaKsGFbwIISEBnC9xteiNKFYEuIncFH668IkhIQWTPAhhBBCPECxJIQQQjxAsSSEEEI8kNSqE1RR5ogQQoh1uf5/OuBN4QLLieWNGzf0f38sAE0IISQydAE1YmPDcoXU//33Xzlz5oykS5cuXpPHMSKB4J48eZIF2e1gv7iHfeMa9ot72DeB7RfIH4Qyd+7cDqtbucJyliU6JG/evH7bHw4UT+KYsF/cw75xDfvFPeybwPWLJ4vShAk+hBBCiAcoloQQQogHKJZxJEWKFDJ8+HD9n/wP9ot72DeuYb+4h30TOv1iuQQfQgghxFdoWRJCCCEeoFgSQgghHqBYEkIIIR6gWBJCCCEeoFjGwuTJk6VgwYKSMmVKqVGjhmzcuDHW7b///nspWbKkbl+uXDlZsmSJWL1fpk2bJnXr1pVMmTLpo1GjRh770UrnjMncuXO1olTr1q0lEvG1X65duya9e/fWRbWR8Vi8eHFeT//HpEmTpESJEpIqVSqtYtOvXz+5e/euRBJ//vmntGjRQivr4Lr46aefPH5m9erVUrlyZT1fihYtKjNmzPBvo5ANS2Iyd+5cI3ny5Mb06dON3bt3G927dzcyZsxonD9/3uX2f/31l5EkSRJj3Lhxxp49e4yhQ4cayZIlM3bu3GlYuV86dOhgTJ482di6dauxd+9eo2vXrkaGDBmMU6dOGZGGr31jcvToUSNPnjxG3bp1jVatWhlW75fo6GijatWqRrNmzYy1a9dq/6xevdrYtm2bYfW++fbbb40UKVLo/+iXZcuWGbly5TL69etnRBJLliwxhgwZYixcuBCzNYwff/wx1u2PHDlipE6d2ujfv7/efz/55BO9Hy9dutRvbaJYuqF69epG7969bc8fPnxo5M6d2xg7dqzL7Z999lmjefPmDq/VqFHDeOmllwwr94szDx48MNKlS2fMnDnTiDTi0jfoj9q1axtffvml0aVLl4gUS1/75fPPPzcKFy5s3Lt3z4h0fO0bbNugQQOH1yAQderUMSIV8UIs33zzTaNMmTIOr7Vr185o0qSJ39pBN6wL7t27J5s3b1aXoX1NWTxft26dy8/gdfvtQZMmTdxub5V+ceb27dty//59yZw5s0QSce2bkSNHSvbs2eWFF16QSCQu/bJo0SKpVauWumFz5MghZcuWlTFjxsjDhw/F6n1Tu3Zt/Yzpqj1y5Ii6p5s1ayZWZl0C3H8tV0jdGy5duqQXJi5Ue/B83759Lj9z7tw5l9vjdSv3izNvvfWWxiGcT2wr9s3atWvlq6++km3btkmkEpd+gQD8/vvv0rFjRxWCQ4cOycsvv6yDLFRtsXLfdOjQQT/3yCOP6IoZDx48kJ49e8rgwYPFypxzc//F6iR37tzR+G58oWVJEoz33ntPE1l+/PFHTWawMlgWqFOnTpoAlTVr1mA3J+SW0YO1/cUXX0iVKlWkXbt2MmTIEJkyZYpYHSSxwMr+7LPPZMuWLbJw4UJZvHixjBo1KthNi3hoWboAN68kSZLI+fPnHV7H85w5c7r8DF73ZXur9IvJBx98oGK5YsUKKV++vEQavvbN4cOH5dixY5rxZy8SIGnSpLJ//34pUqSIWPGcQQZssmTJ9HMmpUqVUusBrsvkyZNLJBCXvnn77bd1kPXiiy/qc2Td37p1S3r06KEDCk9rMkYqOd3cf7F8lz+sSmDNnvUALkaMaFeuXOlwI8NzxFJcgdfttwfLly93u71V+gWMGzdOR75Lly6VqlWrSiTia99gitHOnTvVBWs+WrZsKfXr19e/MSXAqudMnTp11PVqDh7AgQMHVEQjRSjj2jeI+TsLojmosHKZ71oJcf/1W6pQBKZ0I0V7xowZmorco0cPTek+d+6cvt+pUydj4MCBDlNHkiZNanzwwQc6RWL48OERO3XEl3557733NDV+wYIFxtmzZ22PGzduGJGGr33jTKRmw/raLydOnNCM6T59+hj79+83fv31VyN79uzG6NGjDav3De4r6Js5c+bodIn//ve/RpEiRTQbP5K4ceOGTjfDAzI1ceJE/fv48eP6PvoEfeM8deSNN97Q+y+mq3HqSAKCuTr58+fXmz1SvNevX297r169enpzs2f+/PlG8eLFdXukMS9evNiwer8UKFBAT3bnBy76SMTXc8YKYhmXfvn777916hWEBNNI3n33XZ1mY/W+uX//vvHOO++oQKZMmdLIly+f8fLLLxtXr141IolVq1a5vG+YfYH/0TfOn6lYsaL2I86Zr7/+2q9t4hJdhBBCiAcYsySEEEI8QLEkhBBCPECxJIQQQjxAsSSEEEI8QLEkhBBCPECxJIQQQjxAsSSEEEI8QLEkhBBCPECxJH5nxowZkjFjRglXEiVKJD/99FOs23Tt2lVat26dYG0i4XnuYKmtmjVr6io7FStW1OL52MbbZdl4noUOFEvi9iLFRe38QIHrUBBjsz0oKp03b17p1q2bXLhwwS/7P3v2rDRt2lT/dndz++ijj7QdgeSdd96x/U4Uy0ZxdawuceXKFZ/2E0o33FdffVWLh6dIkULFw19cvHhRevXqJfnz59d9YxUKLP77119/SUJif+4ArL+ZJk0aXUUGhb5xDLENFrT2Bufz7LHHHpPXXnstIG0nscMluohbnnjiCfn6668dXsuWLZuEAlh6BzcgrNKwfft2FcszZ87IsmXL4r1vb5ZVy5AhgyQEZcqU0WXNsEjw3r175fnnn5eoqCiZN2+ehCv4DRs2bJAdO3b4bZ9PP/20Lt81c+ZMKVy4sC7PBHG6fPmyJCTO5w6WYmvevLkUKFDA7TahcJ4RL/BrpVkSMcRW1HvChAlG2bJltcp/3rx5jV69ejmsIoICxhkyZLA937Ztm/HYY48ZadOm1RUTKleubPzzzz+299esWWM88sgjWhga+3vllVeMmzdvum2b8/4BCm0nTpzYuH37tvHw4UNjxIgRRp48ebSocoUKFYzffvvNtm10dLTRu3dvI2fOnFqoG0Wsx4wZY3sfl8WPP/5o+9v+YRZvtu+fqVOnGrly5dLvtadly5ZGt27dbM9/+ukno1KlSvqdhQoV0oLYKIztDhSbR9vt6d+/v5EpUybbcxQXf/75542CBQtq/6GQ/6RJkxz24fwbUHDaXN3jmWee0b7EPtHeo0ePGgmBq98WV1BEHL9r9erVsW6HbT777DPjiSee0L7CMfj+++8dtvGmT7766iujdOnSem7hHMK55M25g9+MfeFvrKBhsmvXLqN58+Z6beAawbVw6NChGOcZ/nbeJ1bbQFH18ePHO7TRXK3j4MGDce5X4gjdsMRn4Pr8+OOPZffu3TqS//333+XNN990u33Hjh3VVfrPP//I5s2bZeDAgbq4rznyhgULywCWBiymtWvXSp8+fXxqExZ4hZX54MEDdV1NmDBBF5zGPuGOw1qRBw8e1G3R9kWLFsn8+fPVOv3222+lYMGCLve7ceNG/R/WHdxnWJnemWeeeUYtmFWrVtleg6sU63fit4M1a9ZI586dpW/fvrJnzx6ZOnWqutfeffddr38jXMKwnO3XdMRvRt9+//33ut9hw4bJ4MGD9beBAQMGyLPPPqt9jPbjUbt2bbl//772S7p06bRtcFemTZtWt4OF5g5sE9ujZ8+ektCY341YYXR0dKzbYvFknGvwRuDYPPfcc2qxA2/65PPPP5fevXurOxzrkeI8Klq0qMvvQl/DM/D666/r3zgWzpw+fVoeffRRdR3jOsL1Acsb57EzOK+xPmP37t1txxJuZ2zv7AHCc+zXXdtIHHAST0Jso1isB5cmTRrbo23bti63xeg8S5Ysbi0/jJixXp8rXnjhBV3Dzx5YmrAS79y54/Izzvs/cOCAWlRVq1bV57lz51ZL055q1arpUkYAlmuDBg2Mf//91+X+7a0DV5aAK8sbf8PCM4G1iXaY1mbDhg0drFcwe/ZstUjdAUsE/YC+hyVkWhNY2y82YOk8/fTTbttqfneJEiUc+gAWd6pUqYxly5a53Tcsldge58+fj7VtgbAsAdZLhSWIfqpdu7YxaNAgY/v27Q7boO969uzp8BqWAYNnxNs+wTEdMmSI23bYnzsAv9F+OTrn8wnthIV77949l/tzPnbwbPTt29dhm9OnT+u1umHDBn2OfWXNmtXtNUfiBmOWxC3169fXkbQJEhVMK2vs2LGa6Xf9+nUdBd+9e1dXcU+dOnWM/fTv319efPFFmT17tjRq1EgtsSJFiuh7GOHD+oN1Z4J7Diymo0ePSqlSpVy2DXE7jPqxHb77kUcekS+//FLbg9hlnTp1HLbHc3yXmfDSuHFjKVGihFoNTz75pDz++OPx6itYKRjxf/bZZ2ol4PfAajFXtcd3w1KxtyQRh4yt3wDaCOsF233zzTeaaPTKK684bDN58mSZPn26nDhxQu7cuaNWkKfkGbQHyVqwouzB98Dad0dCWyqwVPG7TW7evOlyO1iLiA3CIly/fr389ttvMm7cOD0ncLxNYJnZg+dm8panPkECGc6thg0b+u334bvr1q1r87TEhdy5c+tvxzlQvXp1+eWXX9TCxnVG/AfFkrgF4uh8c4QrEOKCzEPc+DNnzqxu0xdeeEFv0q5u+sjq7NChgyxevFhvYsgQnDt3rjz11FN683vppZc0S9IZuJjcgRvali1bVIxy5cqlblgAsfRE5cqVVYjRFgg/3JQQ8QULFkhcadGihYo8fmO1atX0pv3hhx/a3sfvHDFihLRp0ybGZzGtwB1wuZrH4L333tObIvYzatQofQ39CPce3M648aNfxo8frwk0sYH2ICvVfpDiTRIXBiix8Z///EemTJki/mLkyJEu3ZeuQD9iEIQH3K0YoOFcsxfL+PSJOfDxJ+Z5G1/wWzt16qTnHFyw7dq1czsAI3GDYkl8AjEVWHO4OZs3DzM+FhvFixfXR79+/aR9+/Z6QUMsIVyItflqseC7XX0GWbIYacOKq1evnu11PMeo23473FDwaNu2rVqYiDNC/O0x44OwAj3dqCGEuNHCOoFFiN9mgr8RH42vZTZ06FBp0KCBDlbM34kY5Msvv2zbxtkyxG9wbj/ag/hw9uzZtS+8xdP8QF/25Q1oHx5xoXTp0jHmy8LqROzY/nmlSpW87hPEtpFlC6+LPyhfvrzG/REv9ca6dHUsQbNmzXRwC08QYuV//vmnX9pH/gcTfIhP4GaPC/uTTz6RI0eOqGs1NksCbkEk66xevVqOHz+uN3ck+pju1bfeekv+/vtv3QY3YiTh/Pzzzz4n+NjzxhtvyPvvv683PggUEoqwbyTXgIkTJ8qcOXPUjXzgwAFNjkE6v6tCCrhxYvSPGxCmI8D9G5srFpYl3GFmYo8JEm9mzZqlViESo5BUAqsQ4ucLsB5xgx0zZow+L1asmGzatEkTf/BbYFGhf51v8HB1oy8uXbqkxw/ty5o1q7Rq1UqtYFjaOEaw8E+dOhXr8Y/t4UnYMJDAsTh37pyeG/gbj9iSijyB5CoMIOCuxe/Eb8ExhRsWv88evI7jg76C1YkELvNc86ZP4CXBQBFJYjhX4d3AtRBX8N3whsBlj+OIfeKawrFyBY4lvAbw8OBYYuAKMA8XFvSgQYP0nHB2NxM/EMdYJ7Hw1BEkmCAxBYkPTZo0MWbNmqVJC0jhd07AQYLEc889Z+TLl09T7ZEg0adPH4fknY0bNxqNGzfWtHkks5QvXz5Ggo6nqSP2IKkG0zIwdSRZsmQxpo588cUXRsWKFfW70qdPr8k3W7ZscZukMW3aNG0/km1cTR2x/170Cz5/+PDhGO1aunSpJp+g3/C91atX17b4mgQzZ84cnX6CaQ537941unbtqv2RMWNGTVYZOHCgw+cuXLhg61/7qSNnz541OnfurMkg2F/hwoWN7t27G1FRUUagQP85T3/AIz5TVtAH+M2YkoR+wJQmJOoMHTpUpxKZ4HsmT56sfYHfi+k28+bNc9iXN30yZcoU3T/OLRxvJIzFNcEHIBHp8ccf13YjGa5u3bq288f5PNu/f79Rs2ZNPYec+w2fwWvjxo2Lc18S9yTCP/4QXUIICWVQCenHH38MmWpG/gbWMJKPTp48KTly5Ah2cyIOxiwJISSMQeYryv3BRYwMWAplYGDMkhBCwhjE31FO79q1axqnJYGBblhCCCHEA7QsCSGEEA9QLAkhhBAPUCwJIYQQD1AsCSGEEA9QLAkhhBAPUCwJIYQQD1AsCSGEEA9QLAkhhBCJnf8H+SKn9wD29wEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUROC: 0.995 (95% CI: 0.993, 0.997)\n"
     ]
    }
   ],
   "source": [
    "# Predict on training data with the neural network\n",
    "def predict_proba_nn(model, X):\n",
    "    # Convert to numpy if DataFrame\n",
    "    if hasattr(X, 'values'):\n",
    "        X = X.values\n",
    "        \n",
    "    # Convert to tensor\n",
    "    device = next(model.parameters()).device\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataset = TensorDataset(X_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=64)\n",
    "    \n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs in dataloader:\n",
    "            inputs = inputs[0].to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            predictions.extend(probs)\n",
    "    \n",
    "    # Convert to the same format as GBM output (two columns: [1-p, p])\n",
    "    probs_array = np.column_stack((1 - np.array(predictions), np.array(predictions)))\n",
    "    return probs_array\n",
    "\n",
    "# Predict on training data\n",
    "pred_probas_train = predict_proba_nn(final_model, X_train)\n",
    "risk_groups_train = results(pred_probas_train)\n",
    "\n",
    "# Compute ROC curve and area under the curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train, pred_probas_train[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plot_PyTorch_ROC_curve(fpr, tpr, roc_auc, 'Training curve: Derivation cohort (ROC curves)')\n",
    "\n",
    "# Compute AUROC CI\n",
    "auroc_ci_lower_train, auroc_ci_upper_train = bootstrap_metric_ci(y_train, pred_probas_train[:,1], \"auroc\")\n",
    "print(f\"Training AUROC: {roc_auc:.3f} (95% CI: {auroc_ci_lower_train:.3f}, {auroc_ci_upper_train:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55c12eda-1fd8-494b-a602-3f8aa9a2b529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUROC: 0.912 (95% CI: 0.858, 0.958)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"\\nVal\")\n",
    "pred_probas_val = predict_proba_nn(final_model, X_test)\n",
    "\n",
    "# Compute ROC curve and area under the curve for validation set\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, pred_probas_val[:,1])\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "plot_PyTorch_ROC_curve(fpr_test, tpr_test, roc_auc_test, 'Validation curve: Derivation cohort (ROC curves)')\n",
    "\n",
    "# Compute AUROC CI\n",
    "auroc_ci_lower_test, auroc_ci_upper_test = bootstrap_metric_ci(y_test, pred_probas_val[:,1], \"auroc\")\n",
    "print(f\"Val AUROC: {roc_auc_test:.3f} (95% CI: {auroc_ci_lower_test:.3f}, {auroc_ci_upper_test:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb48b49-d5a4-4e4f-8e55-774a3a8f7d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
